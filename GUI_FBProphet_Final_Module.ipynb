{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b70b40a6",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e9eeef; border-right: 10px solid #36b38d ;\" height=300 width=100%>\n",
    "    <font color=#2b3444 size=8 align=left ><strong> Revenue Forecasting</strong></font><br>\n",
    "    <font color=#36b38d size=6 align=left ><strong> Model Training Interface</strong></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71114230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipywidgets as widgets\n",
    "from ipywidgets import FileUpload\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import time\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.base import TransformerMixin\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import Image\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from IPython.display import display\n",
    "\n",
    "import pickle\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.plot import plot_cross_validation_metric \n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da5c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63993fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Functions declared for FBProphet Starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab546942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionTosaveL1ForamatedData(GCP_File,AWS_File,BFSI_File,HCLS_File,TMEG_File,data_ver):\n",
    "    if data_ver=='V1':\n",
    "        GCP_File.to_csv(r'RF-GCP-V1-30day.csv', index = False)\n",
    "        AWS_File.to_csv(r'RF-AWS-V1-30day.csv', index = False)\n",
    "        BFSI_File.to_csv(r'RF-BFSI-V1-30day.csv', index = False)\n",
    "        HCLS_File.to_csv(r'RF-HCLS-V1-30day.csv', index = False)\n",
    "        TMEG_File.to_csv(r'RF-TMEG-V1-30day.csv', index = False)\n",
    "    elif data_ver=='V2':\n",
    "        GCP_File.to_csv(r'RF-GCP-V2-30day.csv', index = False)\n",
    "        AWS_File.to_csv(r'RF-AWS-V2-30day.csv', index = False)\n",
    "        BFSI_File.to_csv(r'RF-BFSI-V2-30day.csv', index = False)\n",
    "        HCLS_File.to_csv(r'RF-HCLS-V2-30day.csv', index = False)\n",
    "        TMEG_File.to_csv(r'RF-TMEG-V2-30day.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5074f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionTosaveL0ForamatedData(L0_File,data_ver):\n",
    "    if data_ver=='V3':\n",
    "        L0_File.to_csv(r'RF-L0_V3.csv', index = False)\n",
    "    elif data_ver=='V4':\n",
    "        L0_File.to_csv(r'RF-L0_V4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d80072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function declaration for data Formatting(FBProphet)Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7db497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionTosaveL2ForamatedData(df_bfsi_gcp,df_bfsi_aws,df_bfsi_dir,df_gcp_Region_USEast,df_gcp_Region_USWest,df_gcp_Region_USCentral,df_gcp_Practice_DA,df_gcp_Practice_CAI,data_ver):\n",
    "    if data_ver=='V1':\n",
    "        df_bfsi_gcp.to_csv(r'RF-BFSI-V1-GCP.csv', index = False)\n",
    "        df_bfsi_aws.to_csv(r'RF-BFSI-V1-AWS.csv', index = False)\n",
    "        df_bfsi_dir.to_csv(r'RF-BFSI-V1-DIR.csv', index = False)\n",
    "        df_gcp_Region_USEast.to_csv(r'RF-GCP-Region-USEast.csv', index = False)\n",
    "        df_gcp_Region_USWest.to_csv(r'RF-GCP-Region-USWest.csv', index = False)\n",
    "        df_gcp_Region_USCentral.to_csv(r'RF-GCP-Region-USCentral.csv', index = False)\n",
    "        df_gcp_Practice_DA.to_csv(r'RF-GCP-Practice-DA.csv', index = False)\n",
    "        df_gcp_Practice_CAI.to_csv(r'RF-GCP-Practice-CAI.csv', index = False)\n",
    "    elif data_ver=='V2':\n",
    "        df_bfsi_gcp.to_csv(r'RF-BFSI-V2-GCP.csv', index = False)\n",
    "        df_bfsi_aws.to_csv(r'RF-BFSI-V2-AWS.csv', index = False)\n",
    "        df_bfsi_dir.to_csv(r'RF-BFSI-V2-DIR.csv', index = False)\n",
    "        df_gcp_Region_USEast.to_csv(r'RF-GCP-Region-USEast-V2.csv', index = False)\n",
    "        df_gcp_Region_USWest.to_csv(r'RF-GCP-Region-USWest-V2.csv', index = False)\n",
    "        df_gcp_Region_USCentral.to_csv(r'RF-GCP-Region-USCentral-V2.csv', index = False)\n",
    "        df_gcp_Practice_DA.to_csv(r'RF-GCP-Practice-DA-V2.csv', index = False)\n",
    "        df_gcp_Practice_CAI.to_csv(r'RF-GCP-Practice-CAI-V2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b8d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_download_link( df, title = \"Download the Prediction CSV file\", filename = \"formatted-data.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# df = pd.read_csv('./testvoila.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39046eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Function used to aggregate the values for month wise data\n",
    "def timeseries_gen(df):\n",
    "    feat_cols = ['Date', 'L2-L4 Extn', 'L1', 'L1 Extn', 'Pre-Commit', 'Commit', 'Not in pipeline', 'Weight', 'Actuals', 'dealvalue','Leads UW','Weight_test']\n",
    "    df_gen = pd.DataFrame(columns=feat_cols)\n",
    "    months = df[\"Date\"].unique()\n",
    "    stages = ['L2-L4 Extn', 'L1', 'L1 Extn', 'Pre-Commit', 'Commit', 'Not in pipeline']\n",
    "    for month in months:\n",
    "        #print(month)\n",
    "        dftemp = df.loc[(df['Date'] == month)]\n",
    "        data = []\n",
    "        data.append(month)\n",
    "        stg_freq = dftemp['Stage'].value_counts()\n",
    "        # print(stg_freq)\n",
    "        for stage in stages:\n",
    "            if stage in stg_freq.index:\n",
    "                data.append(stg_freq[stage])\n",
    "            else:\n",
    "                data.append(0)\n",
    "        # stg_freq.drop(index='L3')    \n",
    "        data.append(dftemp['Weight'].mean())\n",
    "        data.append(dftemp['Actuals'].sum())\n",
    "        data.append(dftemp['dealvalue'].sum())\n",
    "        data.append(dftemp['Leads UW'].sum())\n",
    "        data.append(dftemp['Weight'].sum())\n",
    "        df_gen.loc[len(df_gen.index)] = data \n",
    "        df_gen.head()\n",
    "        dftemp = dftemp[0:0]\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a35eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Main function for the V2 dataset for Channels and BUs\n",
    "def dataPrepaterionV2(df):\n",
    "    df['Date'] = df.Year.astype(str) + '/' + df.Month.astype(str)\n",
    "    df['Date']= pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "    cols_drop = ['Business Unit', 'dealid', 'industry','Region','billingtype','projectType',\n",
    "             'solcategory', 'Channel', 'businessimpact']\n",
    "    df = df.drop(columns=cols_drop)\n",
    "    # Dropping section in Stage\n",
    "    dropstage = df['Stage'].isin(['lost','On Hold','DA'])\n",
    "    df = df[~dropstage]\n",
    "    # Renaming 'Not in Pipeline' to 'Not in pipeline'\n",
    "    index_stage = df['Stage'].isin(['Not in Pipeline'])\n",
    "    index_stage.value_counts()\n",
    "    df_index=index_stage.index[index_stage]\n",
    "    df.loc[df_index,['Stage']] = 'Not in pipeline'\n",
    "    # Removing the Negative\n",
    "    def evalneg(x):\n",
    "        return x < 0\n",
    "    actuals_neg = df.loc[df['Actuals'].apply(evalneg)]\n",
    "    temp = df[df['Actuals'] >= 0]\n",
    "    df = df[~df.Actuals.isin(actuals_neg.Actuals)]\n",
    "    \n",
    "    # Removing the negative and zero value\n",
    "    def lessthanzero(y):\n",
    "        return y <= 0 \n",
    "    \n",
    "    dealvalue_eval = df.loc[df['dealvalue'].apply(lessthanzero)]\n",
    "    df = df[~df.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "    \n",
    "    rf = timeseries_gen(df)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Main function for the V1 dataset for Channels and BUs\n",
    "def dataPreparationV1(df1,df2,data_class='GCP'):\n",
    "    df2 = df2.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_all = df2.merge(df1.drop_duplicates(), on=['dealid','dealid'],how='left', indicator=True)\n",
    "    df_all['Actuals'] = df_all['Actuals'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    df_all['Region'].fillna(df_all['region'])\n",
    "    cols2 = df_all.select_dtypes(exclude = [np.number, np.datetime64]).columns\n",
    "    df_all[cols2] = df_all[cols2].fillna(df_all[cols2].mode().iloc[0])\n",
    "    colsduration = ['sowstartdate', 'sowenddate', 'projectduration']\n",
    "    missing = df_all[df_all[colsduration].isna().all(1)]\n",
    "    df_all = df_all.drop(columns=['dealcreated', 'closetime', 'wontime', 'losttime'])\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Stage', 'Region','Practice','Business Category1', 'sourceoflead', 'Channel', 'Business Unit', 'Weight', 'Leads UW', 'Actuals','dealvalue', 'industry', 'billingtype', 'solcategory', 'projectType','businessimpact', 'projectduration', 'sowenddate', 'sowstartdate', 'orgname','ownername']]\n",
    "    df_all.Actuals.sum(axis = 0, skipna = True)\n",
    "    own = df_all.loc[df_all['Weight'] == 1.0]\n",
    "    own.groupby(['ownername'])['Actuals'].agg('sum').sort_values(ascending=False).nlargest(20).sum()\n",
    "    df_all['diff_weeks'] = df_all['sowenddate'] - df_all['sowstartdate']\n",
    "    df_all['diff_weeks']=df_all['diff_weeks']/np.timedelta64(1,'W')\n",
    "    df_all['diff_weeks'] = df_all['diff_weeks'].round(1)\n",
    "    df_all['projectduration'] = df_all['projectduration'].fillna(df_all['diff_weeks'])\n",
    "    df_all = df_all.drop(columns=['sowenddate', 'sowstartdate','diff_weeks'])\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Actuals', 'Leads UW','dealvalue','Stage','Weight', 'Region', 'Channel',\n",
    "       'Business Unit','Practice',\n",
    "       'industry', 'billingtype', 'solcategory', 'projectType', \n",
    "       'businessimpact', 'sourceoflead', 'Business Category1']]\n",
    "    if data_class=='GCP':\n",
    "        df_result = df_all.loc[(df_all['Channel'] == 'GCP')]\n",
    "    elif data_class=='AWS':\n",
    "        df_result = df_all.loc[(df_all['Channel'] == 'AWS')]\n",
    "    elif data_class=='BFSI':\n",
    "        df_result = df_all.loc[(df_all['Business Unit'] == 'BFSI')]\n",
    "    elif data_class=='HCLS':\n",
    "        df_result = df_all.loc[(df_all['Business Unit'] == 'HCLS')]\n",
    "    elif data_class=='TMEG':\n",
    "        df_result = df_all.loc[(df_all['Business Unit'] == 'TMEG')]     \n",
    "    return df_result,df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d31a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Main Flow for L2-level Data Formation for XGBoost\n",
    "def dataPrepartaionL2(df1,df2):\n",
    "    df_gcp,df_all=dataPreparationV1(df1,df2,'GCP')\n",
    "    df_gcp_practice = df_gcp.copy()\n",
    "    # Split into BFSI-GCP, BFSI-AWS, BFSI-Direct\n",
    "    df_bf = df_all.loc[df_all['Business Unit'] == 'BFSI']\n",
    "    df_bfsi_gcp = df_bf.loc[df_bf['Channel'] == 'GCP']\n",
    "    df_bfsi_aws = df_bf.loc[df_bf['Channel'] == 'AWS']\n",
    "    df_bfsi_dir = df_bf.loc[df_bf['Channel'] == 'Direct']\n",
    "    \n",
    "    # Split into Region-US-EAST, Region-US-West, Region-US-Central\n",
    "    df_gcp_USEast = df_gcp.loc[(df_gcp['Region'] == 'US-East')]\n",
    "    df_gcp_USWest = df_gcp.loc[(df_gcp['Region'] == 'US-West')]\n",
    "    df_gcp_USCentral = df_gcp.loc[(df_gcp['Region'] == 'US-Central')]\n",
    "    \n",
    "    # Split into Practice-Conversation-AI, Practice-Conversation-DataAnalytics\n",
    "    \n",
    "    #Renaming 'Application Modernization' to 'Data & Analytics'\n",
    "    index_stage = df_gcp_practice['Practice'].isin(['Application Modernization'])\n",
    "    index_stage.value_counts()\n",
    "    df_index=index_stage.index[index_stage]\n",
    "    df_gcp_practice.loc[df_index,['Practice']] = 'Data & Analytics'\n",
    "\n",
    "    #Renaming 'Infrastructure Modernization' to 'Data & Analytics'\n",
    "    index_stage = df_gcp_practice['Practice'].isin(['Infrastructure Modernization'])\n",
    "    index_stage.value_counts()\n",
    "    df_index=index_stage.index[index_stage]\n",
    "    df_gcp_practice.loc[df_index,['Practice']] = 'Data & Analytics'\n",
    "    \n",
    "    df_gcp_Practice_DA = df_gcp_practice.loc[(df_gcp_practice['Practice'] == 'Data & Analytics')]\n",
    "    df_gcp_Practice_CAI = df_gcp_practice.loc[(df_gcp_practice['Practice'] == 'Conversational AI')]\n",
    "    return df_bfsi_gcp,df_bfsi_aws,df_bfsi_dir,df_gcp_USEast,df_gcp_USWest,df_gcp_USCentral,df_gcp_Practice_DA,df_gcp_Practice_CAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Main Flow for L1-level Data Formation for XGBoost and FBProphet\n",
    "def dataPrepartaionL1(df1,df2):\n",
    "    #******* Keep formatting of the V1 Data here \n",
    "    #Example:\n",
    "    #df1 = pd.read_excel('PD SYNC_26 Oct\\'21.xlsx')\n",
    "    #df2 = pd.read_csv('Rev Projections Data Apr\\'20 - Oct\\'21 - 30 Day.csv')\n",
    "    #df=dataPreparationV1(df1,df2,'GCP')\n",
    "    GCP_File_V1,temp=dataPreparationV1(df1,df2,'GCP')\n",
    "    AWS_File_V1,temp=dataPreparationV1(df1,df2,'AWS')\n",
    "    BFSI_File_V1,temp=dataPreparationV1(df1,df2,'BFSI')\n",
    "    HCLS_File_V1,temp=dataPreparationV1(df1,df2,'HCLS')\n",
    "    TMEG_File_V1,temp=dataPreparationV1(df1,df2,'TMEG')\n",
    "\n",
    "    #******* Keep formatting of V2 data here after V1 data is available Eg:GCP_File_V1 = pd.read_csv('RF-GCP-V1-30day.csv')\n",
    "    RF_V2_GCP=dataPrepaterionV2(GCP_File_V1)\n",
    "    RF_V2_AWS=dataPrepaterionV2(AWS_File_V1)\n",
    "    RF_V2_BFSI=dataPrepaterionV2(BFSI_File_V1)\n",
    "    RF_V2_HCLS=dataPrepaterionV2(HCLS_File_V1)\n",
    "    RF_V2_TMEG=dataPrepaterionV2(TMEG_File_V1)\n",
    "    #**** Save the V2 file on clicking a button\n",
    "    return GCP_File_V1,AWS_File_V1,BFSI_File_V1,HCLS_File_V1,TMEG_File_V1,RF_V2_GCP,RF_V2_AWS,RF_V2_BFSI,RF_V2_HCLS,RF_V2_TMEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f453f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Main Flow for L2-level Data Formation for FBProphet\n",
    "def dataPrepartaionL2_FBProphet(df1,df2):\n",
    "    # declaraion of subfunction\n",
    "    def evalneg(x):\n",
    "        return x < 0  \n",
    "    def lessthanzero(y):\n",
    "        return y <= 0     \n",
    "    def timeseries_gen(df):\n",
    "        feat_cols = ['Date', 'L2-L4 Extn', 'L1', 'L1 Extn', 'Pre-Commit', 'Commit', 'Not in pipeline', 'Weight', 'Actuals', 'dealvalue','Leads UW','Weight_test']\n",
    "        df_gen = pd.DataFrame(columns=feat_cols)\n",
    "        months = df[\"Date\"].unique()\n",
    "        stages = ['L2-L4 Extn', 'L1', 'L1 Extn', 'Pre-Commit', 'Commit', 'Not in pipeline']\n",
    "        for month in months: \n",
    "            #print(month)  \n",
    "            dftemp = df.loc[(df['Date'] == month)]\n",
    "            data = []\n",
    "            data.append(month)\n",
    "            stg_freq = dftemp['Stage'].value_counts()\n",
    "            # print(stg_freq)\n",
    "            for stage in stages:\n",
    "                if stage in stg_freq.index:\n",
    "                    data.append(stg_freq[stage])\n",
    "                else:\n",
    "                    data.append(0)\n",
    "            # stg_freq.drop(index='L3')    \n",
    "            data.append(dftemp['Weight'].mean())\n",
    "            data.append(dftemp['Actuals'].sum())\n",
    "            data.append(dftemp['dealvalue'].sum())\n",
    "            data.append(dftemp['Leads UW'].sum())\n",
    "            data.append(dftemp['Weight'].sum())\n",
    "            df_gen.loc[len(df_gen.index)] = data \n",
    "            #df_gen.head()\n",
    "            dftemp = dftemp[0:0] \n",
    "        return df_gen\n",
    "    \n",
    "    # Preprocessing for GCP-region for FBProphet model \n",
    "    def preProcessingL2(df_temp):\n",
    "        df_temp['Date'] = df_temp.Year.astype(str) + '/' + df_temp.Month.astype(str)\n",
    "        df_temp['Date']= pd.to_datetime(df_temp['Date'], format='%Y-%m-%d')\n",
    "        cols_drop = ['Business Unit', 'dealid', 'industry','Region','billingtype','projectType',\n",
    "             'solcategory', 'Channel', 'businessimpact','projectduration','Practice']  \n",
    "        df_temp = df_temp.drop(columns=cols_drop)\n",
    "        index_stage = df_temp['Stage'].isin(['Not in Pipeline'])\n",
    "        index_stage.value_counts()\n",
    "        df_index=index_stage.index[index_stage]\n",
    "        df_temp.loc[df_index,['Stage']] = 'Not in pipeline'\n",
    "        actuals_neg = df_temp.loc[df_temp['Actuals'].apply(evalneg)]\n",
    "        temp = df_temp[df_temp['Actuals'] >= 0]\n",
    "        df_temp = df_temp[~df_temp.Actuals.isin(actuals_neg.Actuals)]\n",
    "        dealvalue_eval = df_temp.loc[df_temp['dealvalue'].apply(lessthanzero)]\n",
    "        df_temp = df_temp[~df_temp.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "        df_filtered_data = timeseries_gen(df_temp)\n",
    "        return df_filtered_data\n",
    "    def preProcessingL2_BFSI(df):\n",
    "        df['Date'] = df.Year.astype(str) + '/' + df.Month.astype(str)\n",
    "        df['Date']= pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "        cols_drop = ['Business Unit', 'dealid', 'industry','Region','billingtype','projectType',\n",
    "                     'solcategory', 'Channel', 'businessimpact']  \n",
    "        df = df.drop(columns=cols_drop)\n",
    "        dropstage = df['Stage'].isin([ 'lost','On Hold','DA'])\n",
    "        df = df[~dropstage]\n",
    "        #Renaming 'Not in Pipeline' to 'Not in pipeline'\n",
    "        index_stage = df['Stage'].isin(['Not in Pipeline'])\n",
    "        index_stage.value_counts()\n",
    "        df_index=index_stage.index[index_stage]\n",
    "        df.loc[df_index,['Stage']] = 'Not in pipeline'\n",
    "        actuals_neg = df.loc[df['Actuals'].apply(evalneg)]\n",
    "        temp = df[df['Actuals'] >= 0]\n",
    "        df = df[~df.Actuals.isin(actuals_neg.Actuals)]\n",
    "        dealvalue_eval = df.loc[df['dealvalue'].apply(lessthanzero)]\n",
    "        df = df[~df.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "        rf= timeseries_gen(df)\n",
    "        rf=rf.sort_values(by=['Date'])\n",
    "        rf.reset_index(inplace=True,drop=True)\n",
    "        return rf\n",
    "    \n",
    "    df2_temp=df2.copy()\n",
    "    df2 = df2.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_all = df2.merge(df1.drop_duplicates(), on=['dealid','dealid'],how='left', indicator=True)\n",
    "    df_all['Actuals'] = df_all['Actuals'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    df_all['Region'].fillna(df_all['region'])\n",
    "    cols2 = df_all.select_dtypes(exclude = [np.number, np.datetime64]).columns\n",
    "    df_all[cols2] = df_all[cols2].fillna(df_all[cols2].mode().iloc[0])\n",
    "    colsduration = ['sowstartdate', 'sowenddate', 'projectduration']\n",
    "    missing = df_all[df_all[colsduration].isna().all(1)]\n",
    "    df_all = df_all.drop(columns=['dealcreated', 'closetime', 'wontime', 'losttime'])\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Stage', 'Region', 'Channel','Practice','Business Unit', 'Weight', 'Leads UW', 'Actuals','dealvalue', 'industry', 'billingtype', 'solcategory', 'projectType','businessimpact', 'projectduration', 'sowenddate', 'sowstartdate']] \n",
    "    dropstage = df_all['Stage'].isin(['lost', 'On Hold','DA'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    df_all['diff_weeks'] = df_all['sowenddate'] - df_all['sowstartdate']\n",
    "    df_all['diff_weeks']=df_all['diff_weeks']/np.timedelta64(1,'W')\n",
    "    df_all['diff_weeks'] = df_all['diff_weeks'].round(1)\n",
    "    df_all['projectduration'] = df_all['projectduration'].fillna(df_all['diff_weeks'])\n",
    "    df_all = df_all.drop(columns=['sowenddate','sowstartdate','diff_weeks'])\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Actuals', 'Leads UW','dealvalue','Stage','Weight', 'Region', 'Channel',\n",
    "       'Business Unit','Practice',\n",
    "       'industry', 'billingtype', 'solcategory', 'projectType',\n",
    "       'businessimpact', 'projectduration']]\n",
    "    df_gcp = df_all.loc[(df_all['Channel'] == 'GCP')]\n",
    "    \n",
    "    ### Split into Regions\n",
    "    # GCP USEast region\n",
    "    df_gcp_USEast = df_gcp.loc[(df_gcp['Region'] == 'US-East')]\n",
    "    df_gcp_USEast=preProcessingL2(df_gcp_USEast)\n",
    "\n",
    "    # GCP USWest region\n",
    "    df_gcp_USWest = df_gcp.loc[(df_gcp['Region'] == 'US-West')]\n",
    "    df_gcp_USWest=preProcessingL2(df_gcp_USWest)\n",
    "\n",
    "    # GCP USCentral region\n",
    "    df_gcp_USCentral = df_gcp.loc[(df_gcp['Region'] =='US-Central')]\n",
    "    df_gcp_USCentral=preProcessingL2(df_gcp_USCentral)\n",
    "    \n",
    "    ### Split into Practice\n",
    "    #Renaming 'Application Modernization' to 'Data & Analytics'\n",
    "    index_stage = df_gcp['Practice'].isin(['Application Modernization'])\n",
    "    df_index=index_stage.index[index_stage]\n",
    "    df_gcp.loc[df_index,['Practice']] = 'Data & Analytics'\n",
    "    #Renaming 'Infrastructure Modernization' to 'Data & Analytics'\n",
    "    index_stage = df_gcp['Practice'].isin(['Infrastructure Modernization'])\n",
    "    df_index=index_stage.index[index_stage]\n",
    "    df_gcp.loc[df_index,['Practice']] = 'Data & Analytics'\n",
    "    \n",
    "    # GCP-Practice- Data & Analytics\n",
    "    df_gcp_Practice_DA = df_gcp.loc[(df_gcp['Practice'] == 'Data & Analytics')]\n",
    "    df_gcp_Practice_DA=preProcessingL2(df_gcp_Practice_DA)\n",
    "    \n",
    "    # GCP-Practice-Conversational AI\n",
    "    df_gcp_Practice_CAI = df_gcp.loc[(df_gcp['Practice'] == 'Conversational AI')]\n",
    "    df_gcp_Practice_CAI=preProcessingL2(df_gcp_Practice_CAI)\n",
    "    \n",
    "    ### Split into BFSI\n",
    "    df_gcp,df_all=dataPreparationV1(df1,df2_temp,'GCP')\n",
    "    \n",
    "    # Split into BFSI-GCP, BFSI-AWS, BFSI-Direct to get V1 data\n",
    "    df_bf = df_all.loc[df_all['Business Unit'] == 'BFSI']\n",
    "    df_bfsi_gcp = df_bf.loc[df_bf['Channel'] == 'GCP']\n",
    "    df_bfsi_aws = df_bf.loc[df_bf['Channel'] == 'AWS']\n",
    "    df_bfsi_dir = df_bf.loc[df_bf['Channel'] == 'Direct']\n",
    "    # Preprocessing to get V2 data\n",
    "    df_bfsi_gcp=preProcessingL2_BFSI(df_bfsi_gcp)\n",
    "    df_bfsi_aws=preProcessingL2_BFSI(df_bfsi_aws)\n",
    "    df_bfsi_dir=preProcessingL2_BFSI(df_bfsi_dir) \n",
    "    return df_gcp_USEast,df_gcp_USWest,df_gcp_USCentral,df_gcp_Practice_DA,df_gcp_Practice_CAI,df_bfsi_gcp,df_bfsi_aws,df_bfsi_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ae322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Main Flow for L0-level Data Formation for FBProphet\n",
    "def dataPrepartaionL0_FbProphet(df1,df2):\n",
    "    df2 = df2.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_all = df2.merge(df1.drop_duplicates(), on=['dealid','dealid'],how='left', indicator=True)\n",
    "    df_all['Actuals'] = df_all['Actuals'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    df_all['Region'].fillna(df_all['region'])\n",
    "    cols2 = df_all.select_dtypes(exclude = [np.number, np.datetime64]).columns\n",
    "    df_all[cols2] = df_all[cols2].fillna(df_all[cols2].mode().iloc[0])\n",
    "    all_cols = df_all.columns.to_list()\n",
    "    req_cols = ['Year', 'Month','Actuals','dealid', 'Stage', 'Region', \n",
    "                'Channel', 'Business Unit', 'Weight', 'Leads UW', \n",
    "                'dealvalue', 'industry', 'billingtype', \n",
    "                'solcategory', 'projectType','businessimpact']\n",
    "    df_all = df_all[req_cols]\n",
    "    dropstage = df_all['Stage'].isin(['lost', 'On Hold', 'DA'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    # Removing the Negative\n",
    "    def evalneg(x):\n",
    "        return x < 0\n",
    "    actuals_neg = df_all.loc[df_all['Actuals'].apply(evalneg)]\n",
    "    df_all = df_all[~df_all.Actuals.isin(actuals_neg.Actuals)]\n",
    "    \n",
    "    # Removing the negative and zero value\n",
    "    def lessthanzero(y):\n",
    "        return y <= 0 \n",
    "    \n",
    "    dealvalue_eval = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "    df_all = df_all[~df_all.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "    df_all = df_all[df_all['dealvalue'].notna()]\n",
    "    df_all = df_all[['Year', 'Month','Actuals','dealid', 'Leads UW','dealvalue','Stage','Weight', 'Region', 'Channel',\n",
    "                  'Business Unit','industry', 'billingtype', 'solcategory', 'projectType','businessimpact']]\n",
    "    #Renaming 'Not in Pipeline' to 'Not in pipeline'\n",
    "    index_stage = df_all['Stage'].isin(['Not in Pipeline'])\n",
    "    index_stage.value_counts()\n",
    "    df_index=index_stage.index[index_stage]\n",
    "    df_all.loc[df_index,['Stage']] = 'Not in pipeline'\n",
    "    df_all['Date'] = df_all.Year.astype(str) + '/' + df_all.Month.astype(str)\n",
    "    df_all['Date']= pd.to_datetime(df_all['Date'], format='%Y-%m-%d')\n",
    "    df_all = df_all.drop(columns=['Year', 'Month'])\n",
    "    rf = timeseries_gen(df_all)\n",
    "    rf=rf[['Date', 'L2-L4 Extn', 'L1', 'L1 Extn', 'Pre-Commit', 'Commit', 'Not in pipeline', 'Weight', 'Actuals', 'Leads UW', 'dealvalue', 'Weight_test']]\n",
    "    rf=rf.sort_values(by=['Date'])\n",
    "    rf.reset_index(inplace=True,drop=True)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56974f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Perprocessing of input test-set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Perprocessing for test set for L0-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b47f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to perprocess the Test data for L0.\n",
    "def dataPrepartaionL0_FbProphet_testdata(df1,df2):\n",
    "    # Declaration of sub function\n",
    "    def timeseries_gen(df):\n",
    "        feat_cols = ['Date', 'L2-L4 Extn', 'L1', 'L1 Extn', 'Pre-Commit', 'Commit', 'Not in Pipeline', 'Weight', 'Leads UW', 'dealvalue', 'Weight_test']\n",
    "        df_gen = pd.DataFrame(columns=feat_cols)\n",
    "        months = df[\"Date\"].unique()\n",
    "        stages = ['L2-L4 Extn', 'L1', 'L1 Extn', 'Pre-Commit', 'Commit', 'Not in Pipeline']\n",
    "        for month in months:\n",
    "            dftemp = df.loc[(df['Date'] == month)]\n",
    "            data = []\n",
    "            data.append(month)\n",
    "            stg_freq = dftemp['Stage'].value_counts()\n",
    "            for stage in stages:\n",
    "                if stage in stg_freq.index:\n",
    "                    data.append(stg_freq[stage])\n",
    "                else:\n",
    "                    data.append(0)\n",
    "            data.append(dftemp['Weight'].mean())\n",
    "            data.append(dftemp['Leads UW'].sum())\n",
    "            data.append(dftemp['dealvalue'].sum())\n",
    "            data.append(dftemp['Weight'].sum())\n",
    "            df_gen.loc[len(df_gen.index)] = data \n",
    "            df_gen.head()\n",
    "            dftemp = dftemp[0:0] \n",
    "        return df_gen\n",
    "    \n",
    "    present_flag = \"Deal ID\" in df2\n",
    "    if present_flag:\n",
    "        df2 = df2.rename(columns={\"Deal ID\": \"dealid\"}) \n",
    "    present_flag = \"Weights\" in df2\n",
    "    if present_flag:\n",
    "        df2 = df2.rename(columns={\"Weights\": \"Weight\"})\n",
    "    present_flag = \"Stages\" in df2\n",
    "    if present_flag:\n",
    "        df2 = df2.rename(columns={\"Stages\": \"Stage\"})\n",
    "    df_all = df2.merge(df1.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    present_flag = \"region\" in df_all\n",
    "    if present_flag:\n",
    "        df_all = df_all.rename(columns={\"region\": \"Region\"}) \n",
    "    cols2 = df_all.select_dtypes(exclude = [np.number, np.datetime64]).columns\n",
    "    df_all[cols2] = df_all[cols2].fillna(df_all[cols2].mode().iloc[0])   \n",
    "    all_cols = df_all.columns.to_list()\n",
    "    req_cols = ['Year', 'Month', 'dealid', 'Stage', 'Region', \n",
    "                'Channel', 'Business Unit', 'Weight', 'Leads UW', \n",
    "                'dealvalue', 'industry', 'billingtype', \n",
    "                'solcategory', 'projectType','businessimpact']\n",
    "    df_all = df_all[req_cols] \n",
    "    dropstage = df_all['Stage'].isin(['lost', 'On Hold', 'DA'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    \n",
    "    def lessthanzero(y):\n",
    "        return y <= 0 \n",
    "\n",
    "    dealvalue_neg = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "    df_all = df_all[~df_all.dealvalue.isin(dealvalue_neg.dealvalue)]\n",
    "    df_all = df_all[df_all['dealvalue'].notna()]\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW','dealvalue','Stage','Weight', 'Region', 'Channel',\n",
    "                  'Business Unit','industry', 'billingtype', 'solcategory', 'projectType','businessimpact']]\n",
    "    rf_v3=df_all.copy()\n",
    "    df_all.loc[df_all['Stage'].str.contains('Not in pipeline'), 'Stage'] = 'Not in Pipeline'\n",
    "    df_all['Date'] = df_all.Year.astype(str) + '/' + df_all.Month.astype(str)\n",
    "    df_all['Date']= pd.to_datetime(df_all['Date'], format='%Y-%m-%d')\n",
    "    df_all = df_all.drop(columns=['Year', 'Month'])\n",
    "    rf_v4 = timeseries_gen(df_all)\n",
    "    return rf_v3,rf_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Perprocessing for test set for L1-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f188698",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to perprocess the Test data for L1.\n",
    "def dataPrepartaionL1_FbProphet_testdata(df1,df2):\n",
    "    # sub-function declaration\n",
    "    def timeseries_gen(df):\n",
    "        feat_cols = ['Date', 'L2-L4 Extn', 'L1', 'L1 Extn', 'Pre-Commit', 'Commit', 'Not in pipeline', 'Weight', 'dealvalue','Leads UW','Weight_test']\n",
    "        df_gen = pd.DataFrame(columns=feat_cols)\n",
    "        months = df[\"Date\"].unique()\n",
    "        stages = ['L2-L4 Extn', 'L1', 'L1 Extn', 'Pre-Commit', 'Commit', 'Not in pipeline']\n",
    "        for month in months:\n",
    "            dftemp = df.loc[(df['Date'] == month)]\n",
    "            data = []\n",
    "            data.append(month)\n",
    "            stg_freq = dftemp['Stage'].value_counts()\n",
    "            for stage in stages:\n",
    "                if stage in stg_freq.index:\n",
    "                    data.append(stg_freq[stage])\n",
    "                else:\n",
    "                    data.append(0)    \n",
    "            data.append(dftemp['Weight'].mean())\n",
    "            data.append(dftemp['dealvalue'].sum())\n",
    "            data.append(dftemp['Leads UW'].sum())\n",
    "            data.append(dftemp['Weight'].sum())\n",
    "            df_gen.loc[len(df_gen.index)] = data \n",
    "            df_gen.head()\n",
    "            dftemp = dftemp[0:0] \n",
    "        return df_gen\n",
    "\n",
    "    def test_preprocess(df):\n",
    "        df['Date'] = df.Year.astype(str) + '/' + df.Month.astype(str)\n",
    "        df['Date']= pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "        cols_drop = ['projectduration','Business Unit', 'dealid', 'industry','Region','billingtype','projectType',\n",
    "             'solcategory', 'Channel', 'businessimpact']\n",
    "        df = df.drop(columns=cols_drop)\n",
    "        dropstage = df['Stage'].isin(['lost', 'On Hold','DA']) # 'Not in pipeline', 'Not in Pipeline', \n",
    "        df = df[~dropstage]\n",
    "        index_stage = df['Stage'].isin(['Not in Pipeline'])\n",
    "        index_stage.value_counts()\n",
    "        df_index=index_stage.index[index_stage]\n",
    "        df.loc[df_index,['Stage']] = 'Not in pipeline'\n",
    "        def lessthanzero(y):\n",
    "            return y <= 0 \n",
    "        dealvalue_eval = df.loc[df['dealvalue'].apply(lessthanzero)]\n",
    "        df = df[~df.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "        return df\n",
    " \n",
    "    present_flag = \"Deal ID\" in df2\n",
    "    if present_flag:\n",
    "        df2 = df2.rename(columns={\"Deal ID\": \"dealid\"}) \n",
    "    present_flag = \"Weights\" in df2\n",
    "    if present_flag:\n",
    "        df2 = df2.rename(columns={\"Weights\": \"Weight\"})\n",
    "    present_flag = \"Stages\" in df2\n",
    "    if present_flag:\n",
    "        df2 = df2.rename(columns={\"Stages\": \"Stage\"})\n",
    "    df_all = df2.merge(df1.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    A=df_all['region'].isnull()\n",
    "    df_all[A]['dealid']\n",
    "    \n",
    "    cols2 = df_all.select_dtypes(exclude = [np.number, np.datetime64]).columns\n",
    "    df_all[cols2] = df_all[cols2].fillna(df_all[cols2].mode().iloc[0])\n",
    "    \n",
    "    colsduration = ['sowstartdate', 'sowenddate', 'projectduration']\n",
    "    missing = df_all[df_all[colsduration].isna().all(1)]\n",
    "    \n",
    "    df_all = df_all.drop(columns=['dealcreated', 'closetime', 'wontime', 'losttime'])\n",
    "    \n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Stage', 'region', 'Channel', 'Business Unit', 'Weight', 'Leads UW','dealvalue', 'industry', 'billingtype', 'solcategory', 'projectType','businessimpact', 'projectduration', 'sowenddate', 'sowstartdate']]\n",
    "\n",
    "    present_flag = \"region\" in df_all\n",
    "    if present_flag:\n",
    "        df_all = df_all.rename(columns={\"region\": \"Region\"}) \n",
    "        \n",
    "    dropstage = df_all['Stage'].isin(['lost', 'On Hold','DA'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    \n",
    "    df_all['diff_weeks'] = df_all['sowenddate'] - df_all['sowstartdate']\n",
    "    df_all['diff_weeks']=df_all['diff_weeks']/np.timedelta64(1,'W')\n",
    "    df_all['diff_weeks'] = df_all['diff_weeks'].round(1)\n",
    "    df_all['projectduration'] = df_all['projectduration'].fillna(df_all['diff_weeks'])\n",
    "    df_all = df_all.drop(columns=['sowenddate', 'sowstartdate','diff_weeks'])\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW','dealvalue','Stage','Weight', 'Region', 'Channel',\n",
    "                     'Business Unit','industry', 'billingtype', 'solcategory', 'projectType','businessimpact', 'projectduration']] \n",
    "    df_gcp = df_all.loc[(df_all['Channel'] == 'GCP')]\n",
    "    df_aws = df_all.loc[(df_all['Channel'] == 'AWS')]\n",
    "    df_bfsi = df_all.loc[df_all['Business Unit'] == 'BFSI']\n",
    "    df_hcls = df_all.loc[df_all['Business Unit'] == 'HCLS']\n",
    "    df_tmeg = df_all.loc[df_all['Business Unit'] == 'TMEG']\n",
    "    \n",
    "    df_gcp=test_preprocess(df_gcp)\n",
    "    df_aws=test_preprocess(df_aws)\n",
    "    df_bfsi=test_preprocess(df_bfsi)\n",
    "    df_hcls=test_preprocess(df_hcls)\n",
    "    df_tmeg=test_preprocess(df_tmeg)\n",
    "    \n",
    "    RF_V2_GCP = timeseries_gen(df_gcp)\n",
    "    RF_V2_AWS = timeseries_gen(df_aws)\n",
    "    RF_V2_BFSI = timeseries_gen(df_bfsi)\n",
    "    RF_V2_HCLS = timeseries_gen(df_hcls)\n",
    "    RF_V2_TMEG = timeseries_gen(df_tmeg)\n",
    "    return RF_V2_GCP,RF_V2_AWS,RF_V2_BFSI,RF_V2_HCLS,RF_V2_TMEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Perprocessing for test set for L2-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to perprocess the Test data for L2.\n",
    "def dataPrepartaionL2_FBProphet_testdata(df1,df2):\n",
    "    # sub-function declaration\n",
    "    def timeseries_gen(df):\n",
    "        feat_cols = ['Date', 'L2-L4 Extn', 'L1', 'L1 Extn', 'Pre-Commit', 'Commit', 'Not in pipeline', 'Weight', 'dealvalue','Leads UW','Weight_test']\n",
    "        df_gen = pd.DataFrame(columns=feat_cols)\n",
    "        months = df[\"Date\"].unique()\n",
    "        stages = ['L2-L4 Extn', 'L1', 'L1 Extn', 'Pre-Commit', 'Commit', 'Not in pipeline']\n",
    "        for month in months:\n",
    "            dftemp = df.loc[(df['Date'] == month)]\n",
    "            data = []\n",
    "            data.append(month)\n",
    "            stg_freq = dftemp['Stage'].value_counts()\n",
    "            for stage in stages:\n",
    "                if stage in stg_freq.index:\n",
    "                    data.append(stg_freq[stage])\n",
    "                else:\n",
    "                    data.append(0)    \n",
    "            data.append(dftemp['Weight'].mean())\n",
    "            data.append(dftemp['dealvalue'].sum())\n",
    "            data.append(dftemp['Leads UW'].sum())\n",
    "            data.append(dftemp['Weight'].sum())\n",
    "            df_gen.loc[len(df_gen.index)] = data \n",
    "            df_gen.head()\n",
    "            dftemp = dftemp[0:0] \n",
    "        return df_gen\n",
    "\n",
    "    def test_preprocess(df,dataset='others'):\n",
    "        df['Date'] = df.Year.astype(str) + '/' + df.Month.astype(str)\n",
    "        df['Date']= pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "        if dataset=='others':\n",
    "            cols_drop = ['projectduration','Business Unit', 'dealid', 'industry','Region','billingtype','projectType',\n",
    "                         'solcategory', 'Channel', 'businessimpact']\n",
    "        elif dataset=='Region':\n",
    "            cols_drop = ['projectduration','Business Unit', 'dealid', 'industry','billingtype','projectType',\n",
    "                         'solcategory', 'Channel', 'businessimpact']\n",
    "            \n",
    "        df = df.drop(columns=cols_drop)\n",
    "        dropstage = df['Stage'].isin(['lost', 'On Hold','DA']) # 'Not in pipeline', 'Not in Pipeline', \n",
    "        df = df[~dropstage]\n",
    "        index_stage = df['Stage'].isin(['Not in Pipeline'])\n",
    "        index_stage.value_counts()\n",
    "        df_index=index_stage.index[index_stage]\n",
    "        df.loc[df_index,['Stage']] = 'Not in pipeline'\n",
    "        def lessthanzero(y):\n",
    "            return y <= 0 \n",
    "        dealvalue_eval = df.loc[df['dealvalue'].apply(lessthanzero)]\n",
    "        df = df[~df.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "        return df    \n",
    "    \n",
    "    present_flag = \"Deal ID\" in df2\n",
    "    if present_flag:\n",
    "        df2 = df2.rename(columns={\"Deal ID\": \"dealid\"}) \n",
    "    present_flag = \"Weights\" in df2\n",
    "    if present_flag:\n",
    "        df2 = df2.rename(columns={\"Weights\": \"Weight\"})\n",
    "    present_flag = \"Stages\" in df2\n",
    "    if present_flag:\n",
    "        df2 = df2.rename(columns={\"Stages\": \"Stage\"})\n",
    "    df_all = df2.merge(df1.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    A=df_all['region'].isnull()\n",
    "    df_all[A]['dealid']\n",
    "    cols2 = df_all.select_dtypes(exclude = [np.number, np.datetime64]).columns\n",
    "    df_all[cols2] = df_all[cols2].fillna(df_all[cols2].mode().iloc[0])\n",
    "    colsduration = ['sowstartdate', 'sowenddate', 'projectduration']\n",
    "    missing = df_all[df_all[colsduration].isna().all(1)]\n",
    "    df_all = df_all.drop(columns=['dealcreated', 'closetime', 'wontime', 'losttime'])\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Stage', 'region', 'Channel', 'Business Unit', 'Weight', 'Leads UW','dealvalue', 'industry', 'billingtype', 'solcategory', 'projectType','businessimpact', 'projectduration', 'sowenddate', 'sowstartdate']]\n",
    "    present_flag = \"region\" in df_all\n",
    "    if present_flag:\n",
    "        df_all = df_all.rename(columns={\"region\": \"Region\"})  \n",
    "    dropstage = df_all['Stage'].isin(['lost', 'On Hold','DA'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    df_all['diff_weeks'] = df_all['sowenddate'] - df_all['sowstartdate']\n",
    "    df_all['diff_weeks']=df_all['diff_weeks']/np.timedelta64(1,'W')\n",
    "    df_all['diff_weeks'] = df_all['diff_weeks'].round(1)\n",
    "    df_all['projectduration'] = df_all['projectduration'].fillna(df_all['diff_weeks'])\n",
    "    df_all = df_all.drop(columns=['sowenddate', 'sowstartdate','diff_weeks'])\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW','dealvalue','Stage','Weight', 'Region', 'Channel','Business Unit',\n",
    "                     'industry', 'billingtype', 'solcategory', 'projectType','businessimpact', 'projectduration']]\n",
    "\n",
    "\n",
    "    df_bf = df_all.loc[df_all['Business Unit'] == 'BFSI']\n",
    "    df_bfsi_V1_L2_GCP = df_bf.loc[df_bf['Channel'] == 'GCP']           # L2 test set for V1 data(For XGBoost testing)\n",
    "    df_bfsi_V1_L2_AWS = df_bf.loc[df_bf['Channel'] == 'AWS']           # L2 test set for V1 data(For XGBoost testing)\n",
    "    df_bfsi_V1_L2_DIR = df_bf.loc[df_bf['Channel'] == 'Direct']        # L2 test set for V1 data(For XGBoost testing)\n",
    "    \n",
    "    df_gsp_V1_L1 = df_all.loc[df_all['Channel'] == 'GCP']\n",
    "    df_gsp_V1_L1_temp=test_preprocess(df_gsp_V1_L1,dataset='Region')\n",
    "    df_Region_UScentral = df_gsp_V1_L1_temp.loc[(df_gsp_V1_L1_temp['Region'] == 'US-Central')]\n",
    "    df_Region_USeast = df_gsp_V1_L1_temp.loc[(df_gsp_V1_L1_temp['Region'] == 'US-East')]\n",
    "    df_Region_USwest = df_gsp_V1_L1_temp.loc[(df_gsp_V1_L1_temp['Region'] == 'US-West')]\n",
    "        \n",
    "    df_bfsi_V1_L2_GCP=test_preprocess(df_bfsi_V1_L2_GCP)\n",
    "    df_bfsi_V1_L2_AWS=test_preprocess(df_bfsi_V1_L2_AWS)\n",
    "    df_bfsi_V1_L2_DIR=test_preprocess(df_bfsi_V1_L2_DIR)\n",
    "    \n",
    "    df_bfsi_gcp = timeseries_gen(df_bfsi_V1_L2_GCP)\n",
    "    df_bfsi_aws = timeseries_gen(df_bfsi_V1_L2_AWS)\n",
    "    df_bfsi_dir = timeseries_gen(df_bfsi_V1_L2_DIR)\n",
    "    \n",
    "    df_gcp_USCentral = timeseries_gen(df_Region_UScentral)\n",
    "    df_gcp_USEast = timeseries_gen(df_Region_USeast)\n",
    "    df_gcp_USWest = timeseries_gen(df_Region_USwest)\n",
    "\n",
    "    # L2 level prdiction for Practice is commanted temprarly. This is bec input data doesnt had the Practice column. \n",
    "    #This column can be enabled once data is completely given by salesops team. Note: one enabling this section we need to add practice columns in the above filtering the of columns   \n",
    "#     df_Practice_DA = df_gsp_V1_L1_temp.loc[(df_gsp_V1_L1_temp['Practice'] == 'Data & Analytics')]\n",
    "#     df_Practice_CAI = df_gsp_V1_L1_temp.loc[(df_gsp_V1_L1_temp['Practice'] == 'Conversational AI')]\n",
    "#     df_gcp_Practice_DA = timeseries_gen(df_Practice_DA)\n",
    "#     df_gcp_Practice_CAI = timeseries_gen(df_Practice_CAI)\n",
    "#     #,df_gcp_Practice_DA,df_gcp_Practice_CAI\n",
    "    \n",
    "    return df_gcp_USEast,df_gcp_USWest,df_gcp_USCentral,df_bfsi_gcp,df_bfsi_aws,df_bfsi_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56672a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Arrangment: FBProphet\n",
    "#In this section features are arranged as per the model requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Feature arrangements for L0 and L1-level for FBProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Arrangement for L0-level and L1-level model for FBProphet\n",
    "def featureArrangeL0_L1(df,case='test'):\n",
    "    dfNew_L0=df.copy()\n",
    "    if case=='train':\n",
    "        Columns_consider=['Date','Actuals','dealvalue','L1','L1 Extn','L2-L4 Extn','Pre-Commit','Commit','Leads UW','Not in pipeline','Weight_test']#\n",
    "        dfNew_L0 = dfNew_L0[Columns_consider]\n",
    "        dfNew_L0.rename(columns={'Date':'ds','Actuals':'y','Weight_test':'add1','dealvalue':'add2','L1':'add3','L1 Extn':'add4','L2-L4 Extn':'add5','Pre-Commit':'add6','Commit':'add7','Leads UW':'add8','Not in pipeline':'add9'}, inplace=True)\n",
    "    elif case=='test':\n",
    "        Columns_consider=['Date','dealvalue','L1','L1 Extn','L2-L4 Extn','Pre-Commit','Commit','Leads UW','Not in pipeline','Weight_test']#\n",
    "        dfNew_L0 = dfNew_L0[Columns_consider]\n",
    "        dfNew_L0.rename(columns={'Date':'ds','Weight_test':'add1','dealvalue':'add2','L1':'add3','L1 Extn':'add4','L2-L4 Extn':'add5','Pre-Commit':'add6','Commit':'add7','Leads UW':'add8','Not in pipeline':'add9'}, inplace=True)\n",
    "    return dfNew_L0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Arrangement for L2-level model for FBProphet\n",
    "def featureArrangeL2(df,Database,case='test'):\n",
    "    dfNew1=df.copy()\n",
    "    if Database=='BFSI_GCP':\n",
    "        if case=='train':\n",
    "            Columns_consider=['Date','Actuals','dealvalue','Commit','Leads UW','Weight_test']\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Actuals':'y','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4'}, inplace=True)\n",
    "        elif case=='test':\n",
    "            Columns_consider=['Date','dealvalue','Commit','Leads UW','Weight_test']#\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4'}, inplace=True)\n",
    "    elif Database=='BFSI_AWS':\n",
    "        if case=='train':\n",
    "            Columns_consider=['Date','Actuals','dealvalue','Commit','Leads UW','Weight_test','L1']\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Actuals':'y','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5'}, inplace=True)\n",
    "        elif case=='test':\n",
    "            Columns_consider=['Date','dealvalue','Commit','Leads UW','Weight_test','L1']#\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5'}, inplace=True)\n",
    "    elif Database=='BFSI_DIR':\n",
    "        if case=='train':\n",
    "            Columns_consider=['Date','Actuals','dealvalue','Commit','Leads UW','Weight_test','L1','Not in pipeline']\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Actuals':'y','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5','Not in pipeline':'add6'}, inplace=True)\n",
    "        elif case=='test':\n",
    "            Columns_consider=['Date','dealvalue','Commit','Leads UW','Weight_test','L1','Not in pipeline']#\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5','Not in pipeline':'add6'}, inplace=True)\n",
    "    elif Database=='Region_USCentral':\n",
    "        if case=='train':\n",
    "            Columns_consider=['Date','Actuals','dealvalue','Commit','Leads UW','Weight_test','L1']\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Actuals':'y','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5'}, inplace=True)\n",
    "        elif case=='test':\n",
    "            Columns_consider=['Date','dealvalue','Commit','Leads UW','Weight_test','L1']#\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5'}, inplace=True)\n",
    "    elif Database=='Region_USEast':\n",
    "        if case=='train':\n",
    "            Columns_consider=['Date','Actuals','dealvalue','Commit','Leads UW','Weight_test','L1','L1 Extn','L2-L4 Extn']\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Actuals':'y','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5','L1 Extn':'add6','L2-L4 Extn':'add7'}, inplace=True)\n",
    "        elif case=='test':\n",
    "            Columns_consider=['Date','dealvalue','Commit','Leads UW','Weight_test','L1','L1 Extn','L2-L4 Extn']#\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5','L1 Extn':'add6','L2-L4 Extn':'add7'}, inplace=True)\n",
    "    elif Database=='Region_USWest':\n",
    "        if case=='train':\n",
    "            Columns_consider=['Date','Actuals','dealvalue','Commit','Leads UW','Weight_test','L1','L1 Extn','Not in pipeline']\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Actuals':'y','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5','L1 Extn':'add6','Not in pipeline':'add7'}, inplace=True)\n",
    "        elif case=='test':\n",
    "            Columns_consider=['Date','dealvalue','Commit','Leads UW','Weight_test','L1','L1 Extn','Not in pipeline']#\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5','L1 Extn':'add6','Not in pipeline':'add7'}, inplace=True)\n",
    "    elif Database=='Practice_CAI':\n",
    "        if case=='train':\n",
    "            Columns_consider=['Date','Actuals','dealvalue','Commit','Leads UW','Weight_test','L2-L4 Extn','Pre-Commit','L1','L1 Extn','Not in pipeline']\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Actuals':'y','Weight_test':'add1','dealvalue':'add2','L1':'add3','L1 Extn':'add4','L2-L4 Extn':'add5','Pre-Commit':'add6','Commit':'add7','Leads UW':'add8','Not in pipeline':'add9'}, inplace=True)\n",
    "        elif case=='test':\n",
    "            Columns_consider=['Date','dealvalue','Commit','Leads UW','Weight_test','L2-L4 Extn','Pre-Commit','L1','L1 Extn','Not in pipeline']\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Weight_test':'add1','dealvalue':'add2','L1':'add3','L1 Extn':'add4','L2-L4 Extn':'add5','Pre-Commit':'add6','Commit':'add7','Leads UW':'add8','Not in pipeline':'add9'}, inplace=True)\n",
    "    elif Database=='Practice_DA':\n",
    "        if case=='train':\n",
    "            Columns_consider=['Date','Actuals','dealvalue','Commit','Leads UW','Weight_test','L1','L1 Extn','L2-L4 Extn']\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Actuals':'y','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5','L1 Extn':'add6','L2-L4 Extn':'add7'}, inplace=True)\n",
    "        elif case=='test':\n",
    "            Columns_consider=['Date','dealvalue','Commit','Leads UW','Weight_test','L1','L1 Extn','L2-L4 Extn']\n",
    "            dfNew1 = dfNew1[Columns_consider]\n",
    "            dfNew1.rename(columns={'Date':'ds','Weight_test':'add1','dealvalue':'add2','Commit':'add3','Leads UW':'add4','L1':'add5','L1 Extn':'add6','L2-L4 Extn':'add7'}, inplace=True)\n",
    "    return dfNew1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa041e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### model level preprocess for FBProphet\n",
    "def modelLevel_Preprocessing(df,case='test'):\n",
    "    present_flag = \"Not in Pipeline\" in df\n",
    "    if present_flag:\n",
    "        df = df.rename(columns={\"Not in Pipeline\": \"Not in pipeline\"}) \n",
    "        \n",
    "    if case=='train':\n",
    "        Columns_consider=['Date','Actuals','dealvalue','Weight','L1','L1 Extn','L2-L4 Extn','Pre-Commit','Commit','Leads UW','Not in pipeline','Weight_test']#\n",
    "    elif case=='test':\n",
    "        Columns_consider=['Date','dealvalue','Weight','L1','L1 Extn','L2-L4 Extn','Pre-Commit','Commit','Leads UW','Not in pipeline','Weight_test']#\n",
    "        \n",
    "    df1 = df[Columns_consider]\n",
    "    df1=df1.sort_values(by=['Date'])\n",
    "    df1.reset_index(inplace=True,drop=True)\n",
    "    df1=df1.drop(columns=['Weight'])\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78bc077",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function written for using existing model\n",
    "#Loading the pckl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Calling Train model\n",
    "##  SubFunction Declration\n",
    "# loading L1-Level model # \n",
    "def loadingL1_Model_pcklfile():\n",
    "    with open('model_FBProphet_L1_GCP.pckl', 'rb') as fin:\n",
    "        model_L1_GCP = pickle.load(fin)\n",
    "    with open('model_FBProphet_L1_AWS.pckl', 'rb') as fin:\n",
    "        model_L1_AWS = pickle.load(fin)\n",
    "    with open('model_FBProphet_L1_BFSI.pckl', 'rb') as fin:\n",
    "        model_L1_BFSI = pickle.load(fin)\n",
    "    with open('model_FBProphet_L1_HCLS.pckl', 'rb') as fin:\n",
    "        model_L1_HCLS = pickle.load(fin)\n",
    "    with open('model_FBProphet_L1_TMEG.pckl', 'rb') as fin:\n",
    "        model_L1_TMEG = pickle.load(fin)\n",
    "    return model_L1_GCP,model_L1_AWS,model_L1_BFSI,model_L1_HCLS,model_L1_TMEG\n",
    "    \n",
    "# loading L2-Level model #\n",
    "def loadingL2_Model_pcklfile():\n",
    "    with open('model_FBProphet_L2_BFSI_GCP.pckl', 'rb') as fin:\n",
    "        model_L2_BFSI_GCP = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_BFSI_AWS.pckl', 'rb') as fin:\n",
    "        model_L2_BFSI_AWS = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_BFSI_DIR.pckl', 'rb') as fin:\n",
    "        model_L2_BFSI_DIR = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_GCP_Region_USEast.pckl', 'rb') as fin:\n",
    "        model_L2_Region_USEast = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_GCP_Region_USWest.pckl', 'rb') as fin:\n",
    "        model_L2_Region_USWest = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_GCP_Region_USCentral.pckl', 'rb') as fin:\n",
    "        model_L2_Region_USCentral = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_GCP_Practice_DA.pckl', 'rb') as fin:\n",
    "        model_L2_Practice_DA = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_GCP_Practice_CAI.pckl', 'rb') as fin:\n",
    "        model_L2_Practice_CAI = pickle.load(fin)\n",
    "    return model_L2_BFSI_GCP,model_L2_BFSI_AWS,model_L2_BFSI_DIR,model_L2_Region_USCentral,model_L2_Region_USEast,model_L2_Region_USWest,model_L2_Practice_CAI,model_L2_Practice_DA    \n",
    "# Loading L0-Level model\n",
    "def loadingL0_Model_pcklfile():\n",
    "    with open('model_FBProphet_L0.pckl', 'rb') as fin:\n",
    "        model_L0 = pickle.load(fin)\n",
    "    return model_L0    \n",
    "\n",
    "### Note:\n",
    "# If One has the data which is in month wise or segemention of preprocessed data. Then they can use\n",
    "# step1: modelLevel_Preprocessing\n",
    "# step2: featureArrange for that perticular level\n",
    "# step3: use trained model\n",
    "#########\n",
    "def functionTosaveL0FormattedTestData(df_L0):\n",
    "  df_L0.to_csv(r'Formatted_L0_testdata.csv', index = False)\n",
    "\n",
    "def functionTosaveL1FormattedTestData(RF_V2_GCP,RF_V2_AWS,RF_V2_BFSI,RF_V2_HCLS,RF_V2_TMEG):\n",
    "  RF_V2_GCP.to_csv(r'Formatted_L1_GCP_testdata.csv', index = False)\n",
    "  RF_V2_AWS.to_csv(r'Formatted_L1_AWS_testdata.csv', index = False)\n",
    "  RF_V2_BFSI.to_csv(r'Formatted_L1_BFSI_testdata.csv', index = False)\n",
    "  RF_V2_HCLS.to_csv(r'Formatted_L1_HCLS_testdata.csv', index = False)\n",
    "  RF_V2_TMEG.to_csv(r'Formatted_L1_TMEG_testdata.csv', index = False)\n",
    "\n",
    "def functionTosaveL2FormattedTestData(df_gcp_USEast,df_gcp_USWest,df_gcp_USCentral,df_bfsi_gcp,df_bfsi_aws,df_bfsi_dir):\n",
    "  df_gcp_USEast.to_csv(r'Formatted_L2_df_gcp_USEast.csv', index = False)\n",
    "  df_gcp_USWest.to_csv(r'Formatted_L2_df_gcp_USWest.csv', index = False)\n",
    "  df_gcp_USCentral.to_csv(r'Formatted_L2_df_gcp_USCentral.csv', index = False)\n",
    "  df_bfsi_gcp.to_csv(r'Formatted_L2_df_bfsi_gcp.csv', index = False)\n",
    "  df_bfsi_aws.to_csv(r'Formatted_L2_df_bfsi_aws.csv', index = False)\n",
    "  df_bfsi_dir.to_csv(r'Formatted_L2_df_bfsi_dir.csv', index = False)\n",
    "\n",
    "\n",
    "## Executing on test set  \n",
    "# L0-Level\n",
    "def L0_level_prediction_saved_model(df1,df2,saveflag_data='False'):\n",
    "    temp,df_L0=dataPrepartaionL0_FbProphet_testdata(df1,df2) \n",
    "    if saveflag_data=='True':\n",
    "        functionTosaveL0FormattedTestData(df_L0)\n",
    "    df_L0=modelLevel_Preprocessing(df_L0,case='test')              # Preprocessing as per the model\n",
    "    df_L0=featureArrangeL0_L1(df_L0,case='test')       # Feature arragend as per the model\n",
    "    modelL0=loadingL0_Model_pcklfile()\n",
    "    forecast_L0 = modelL0.predict(df_L0)               # Prediction using the model\n",
    "    Predict_L0=forecast_L0.yhat.values.astype(int)     # Predicted result is made into readable format\n",
    "    return Predict_L0,df_L0\n",
    "\n",
    "def L1_level_prediction_saved_model(df1,df2,saveflag_data='False'):   \n",
    "    RF_V2_GCP,RF_V2_AWS,RF_V2_BFSI,RF_V2_HCLS,RF_V2_TMEG=dataPrepartaionL1_FbProphet_testdata(df1,df2)\n",
    "    if saveflag_data=='True':\n",
    "        functionTosaveL1FormattedTestData(RF_V2_GCP,RF_V2_AWS,RF_V2_BFSI,RF_V2_HCLS,RF_V2_TMEG)\n",
    "\n",
    "    df_L1_GCP=modelLevel_Preprocessing(RF_V2_GCP,case='test')                 # Preprocessing as per the model\n",
    "    df_L1_AWS=modelLevel_Preprocessing(RF_V2_AWS,case='test')                 # Preprocessing as per the model\n",
    "    df_L1_BFSI=modelLevel_Preprocessing(RF_V2_BFSI,case='test')               # Preprocessing as per the model\n",
    "    df_L1_HCLS=modelLevel_Preprocessing(RF_V2_HCLS,case='test')               # Preprocessing as per the model\n",
    "    df_L1_TMEG=modelLevel_Preprocessing(RF_V2_TMEG,case='test')               # Preprocessing as per the model\n",
    "\n",
    "    df_L1_GCP=featureArrangeL0_L1(df_L1_GCP,case='test')          # Feature arragend as per the model\n",
    "    df_L1_AWS=featureArrangeL0_L1(df_L1_AWS,case='test')          # Feature arragend as per the model\n",
    "    df_L1_BFSI=featureArrangeL0_L1(df_L1_BFSI,case='test')        # Feature arragend as per the model\n",
    "    df_L1_HCLS=featureArrangeL0_L1(df_L1_HCLS,case='test')        # Feature arragend as per the model\n",
    "    df_L1_TMEG=featureArrangeL0_L1(df_L1_TMEG,case='test')        # Feature arragend as per the model\n",
    "\n",
    "    model_L1_GCP,model_L1_AWS,model_L1_BFSI,model_L1_HCLS,model_L1_TMEG=loadingL1_Model_pcklfile()\n",
    "\n",
    "    forecast_L1_GCP = model_L1_GCP.predict(df_L1_GCP)             # Prediction using the model\n",
    "    forecast_L1_AWS = model_L1_AWS.predict(df_L1_AWS)             # Prediction using the model\n",
    "    forecast_L1_BFSI = model_L1_BFSI.predict(df_L1_BFSI)          # Prediction using the model\n",
    "    forecast_L1_HCLS = model_L1_HCLS.predict(df_L1_HCLS)          # Prediction using the model\n",
    "    forecast_L1_TMEG = model_L1_TMEG.predict(df_L1_TMEG)          # Prediction using the model\n",
    "\n",
    "    Predict_L1_GCP=forecast_L1_GCP.yhat.values.astype(int)       # Predicted result is made into readable format\n",
    "    Predict_L1_AWS=forecast_L1_AWS.yhat.values.astype(int)       # Predicted result is made into readable format\n",
    "    Predict_L1_BFSI=forecast_L1_BFSI.yhat.values.astype(int)     # Predicted result is made into readable format\n",
    "    Predict_L1_HCLS=forecast_L1_HCLS.yhat.values.astype(int)     # Predicted result is made into readable format\n",
    "    Predict_L1_TMEG=forecast_L1_TMEG.yhat.values.astype(int)     # Predicted result is made into readable format\n",
    "\n",
    "    return Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,df_L1_GCP\n",
    "\n",
    "def L2_level_prediction_saved_model(df1,df2,saveflag_data='False'):\n",
    "    # L2-Level\n",
    "    #df_gcp_USEast,df_gcp_USWest,df_gcp_USCentral,df_gcp_Practice_DA,df_gcp_Practice_CAI,df_bfsi_gcp,df_bfsi_aws,df_bfsi_di\n",
    "    df_gcp_USEast,df_gcp_USWest,df_gcp_USCentral,df_bfsi_gcp,df_bfsi_aws,df_bfsi_dir=dataPrepartaionL2_FBProphet_testdata(df1,df2)\n",
    "    if saveflag_data=='True':\n",
    "        functionTosaveL2FormattedTestData(df_gcp_USEast,df_gcp_USWest,df_gcp_USCentral,df_bfsi_gcp,df_bfsi_aws,df_bfsi_dir)\n",
    "\n",
    "    # Make this section as function ---------------\n",
    "    df_L2_USEast=modelLevel_Preprocessing(df_gcp_USEast,case='test')                # Preprocessing as per the model\n",
    "    df_L2_USWest=modelLevel_Preprocessing(df_gcp_USWest,case='test')                # Preprocessing as per the model\n",
    "    df_L2_USCentral=modelLevel_Preprocessing(df_gcp_USCentral,case='test')          # Preprocessing as per the model\n",
    "#    df_L2_Practice_DA=modelLevel_Preprocessing(df_gcp_Practice_DA,case='test')      # Preprocessing as per the model\n",
    "#    df_L2_Practice_CAI=modelLevel_Preprocessing(df_gcp_Practice_CAI,case='test')    # Preprocessing as per the model\n",
    "    df_L2_bfsi_GCP=modelLevel_Preprocessing(df_bfsi_gcp,case='test')                # Preprocessing as per the model\n",
    "    df_L2_bfsi_AWS=modelLevel_Preprocessing(df_bfsi_aws,case='test')                # Preprocessing as per the model\n",
    "    df_L2_bfsi_DIR=modelLevel_Preprocessing(df_bfsi_dir,case='test')                # Preprocessing as per the model\n",
    "\n",
    "    df_L2_bfsi_GCP=featureArrangeL2(df_L2_bfsi_GCP,Database='BFSI_GCP',case='test')                    # Feature arragend as per the model\n",
    "    df_L2_bfsi_AWS=featureArrangeL2(df_L2_bfsi_AWS,Database='BFSI_AWS',case='test')                    # Feature arragend as per the model\n",
    "    df_L2_bfsi_DIR=featureArrangeL2(df_L2_bfsi_DIR,Database='BFSI_DIR',case='test')                    # Feature arragend as per the model\n",
    "    df_L2_USCentral=featureArrangeL2(df_L2_USCentral,Database='Region_USCentral',case='test')          # Feature arragend as per the model\n",
    "    df_L2_USEast=featureArrangeL2(df_L2_USEast,Database='Region_USEast',case='test')                   # Feature arragend as per the model\n",
    "    df_L2_USWest=featureArrangeL2(df_L2_USWest,Database='Region_USWest',case='test')                   # Feature arragend as per the model\n",
    "#    df_L2_Practice_CAI=featureArrangeL2(df_L2_Practice_CAI,Database='Practice_CAI',case='test')        # Feature arragend as per the model\n",
    "#    df_L2_Practice_DA=featureArrangeL2(df_L2_Practice_DA,Database='Practice_DA',case='test')           # Feature arragend as per the model\n",
    "\n",
    "    model_L2_BFSI_GCP,model_L2_BFSI_AWS,model_L2_BFSI_DIR,model_L2_Region_USCentral,model_L2_Region_USEast,model_L2_Region_USWest,model_L2_Practice_CAI,model_L2_Practice_DA=loadingL2_Model_pcklfile()\n",
    "\n",
    "    forecast_L2_bfsi_GCP = model_L2_BFSI_GCP.predict(df_L2_bfsi_GCP)                  # Prediction using the model\n",
    "    forecast_L2_bfsi_AWS = model_L2_BFSI_AWS.predict(df_L2_bfsi_AWS)                  # Prediction using the model\n",
    "    forecast_L2_bfsi_DIR = model_L2_BFSI_DIR.predict(df_L2_bfsi_DIR)                  # Prediction using the model\n",
    "    forecast_L2_USCentral = model_L2_Region_USCentral.predict(df_L2_USCentral)        # Prediction using the model\n",
    "    forecast_L2_USEast = model_L2_Region_USEast.predict(df_L2_USEast)                 # Prediction using the model\n",
    "    forecast_L2_USWest = model_L2_Region_USWest.predict(df_L2_USWest)                 # Prediction using the model\n",
    "#    Practice_CAI = model_L2_Practice_CAI.predict(df_L2_Practice_CAI)      # Prediction using the model\n",
    "#    Practice_DA = model_L2_Practice_DA.predict(df_L2_Practice_DA)         # Prediction using the model\n",
    "\n",
    "    bfsi_GCP=forecast_L2_bfsi_GCP.yhat.values.astype(int)       # Predicted result is made into readable format\n",
    "    bfsi_AWS=forecast_L2_bfsi_AWS.yhat.values.astype(int)       # Predicted result is made into readable format\n",
    "    bfsi_DIR=forecast_L2_bfsi_DIR.yhat.values.astype(int)     # Predicted result is made into readable format\n",
    "    USCentral=forecast_L2_USCentral.yhat.values.astype(int)     # Predicted result is made into readable format\n",
    "    USEast=forecast_L2_USEast.yhat.values.astype(int)     # Predicted result is made into readable format\n",
    "    USWest=forecast_L2_USWest.yhat.values.astype(int)     # Predicted result is made into readable format\n",
    "\n",
    "    return bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,df_L2_bfsi_GCP         #,Practice_CAI,Practice_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function written for training the FBProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Functions for retraining the model on new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f090c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model training for FBProphet\n",
    "#### Given the data and number of validation month information. The function will return the trained model and the MAPE\n",
    "## L0,L1-level model\n",
    "def rmse_per(predictions, targets):\n",
    "    targets=targets+0.000001\n",
    "    percentage_error=(np.abs(predictions-targets)/targets)*100\n",
    "    RMSEValue=np.sqrt(((predictions - targets) ** 2).mean())\n",
    "    return RMSEValue,percentage_error\n",
    "\n",
    "def training_L0_L1_model_FBProphet(L0_Data,num_Val=2):\n",
    "    L0_Data1=modelLevel_Preprocessing(L0_Data,case='train')\n",
    "    L0_Data2=featureArrangeL0_L1(L0_Data1,case='train')\n",
    "    \n",
    "    num_months_validation=num_Val\n",
    "    X_train =L0_Data2.loc[0:(L0_Data2.shape[0]-(num_months_validation+1))]\n",
    "    X_val  = L0_Data2.loc[(L0_Data2.shape[0]-num_months_validation):L0_Data2.shape[0]]\n",
    "    X_val.reset_index(inplace=True,drop=True)\n",
    "    modelL0=hyperParameter_tuning_L0_L1(X_train,X_val)\n",
    "    \n",
    "    forecast_val = modelL0.predict(X_val.drop(columns=\"y\"))\n",
    "    df_Result_Val=pd.DataFrame({'actual': X_val.y.values, 'predicted': forecast_val.yhat.values.astype(int)})\n",
    "    df_Result_Val.insert(loc=0, column='Date', value=X_val.ds.values)\n",
    "    A, per_error=rmse_per(np.array(forecast_val['yhat']), np.array(X_val['y']))\n",
    "    #df_Result_Val['Absolute Error']=abs(np.array(forecast_val['yhat'])-np.array(X_val['y']))\n",
    "    #df_Result_Val['Percentage Error']=per_error\n",
    "    #df_Result_Val.reset_index(drop=True, inplace=True)\n",
    "    mape_val=per_error\n",
    "    return modelL0,mape_val\n",
    "## L2-level model\n",
    "def training_L2_model_FBProphet(L2_Data,num_Val=2,Database='BFSI_GCP'):\n",
    "    L2_Data1=modelLevel_Preprocessing(L2_Data,case='train')\n",
    "    L2_Data2=featureArrangeL2(L2_Data1,Database,case='train') \n",
    "    num_months_validation=num_Val\n",
    "    X_train =L2_Data2.loc[0:(L2_Data2.shape[0]-(num_months_validation+1))]\n",
    "    X_val  = L2_Data2.loc[(L2_Data2.shape[0]-num_months_validation):L2_Data2.shape[0]]\n",
    "    X_val.reset_index(inplace=True,drop=True)\n",
    "    modelL2=hyperParameter_tuning_L2(X_train,X_val,Database)\n",
    "    forecast_val = modelL2.predict(X_val.drop(columns=\"y\"))\n",
    "    df_Result_Val=pd.DataFrame({'actual': X_val.y.values, 'predicted': forecast_val.yhat.values.astype(int)})\n",
    "    df_Result_Val.insert(loc=0, column='Date', value=X_val.ds.values)\n",
    "    A, per_error=rmse_per(np.array(forecast_val['yhat']), np.array(X_val['y']))\n",
    "    #df_Result_Val['Absolute Error']=abs(np.array(forecast_val['yhat'])-np.array(X_val['y']))\n",
    "    #df_Result_Val['Percentage Error']=per_error\n",
    "    #df_Result_Val.reset_index(drop=True, inplace=True)\n",
    "    mape_val=per_error\n",
    "    return modelL2,mape_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d85c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### HyperParameter tuning for FBProphet-L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defined for training the L2-level\n",
    "def hyperParameter_tuning_L2(X_train,X_val,Database='BFSI_GCP'):\n",
    "    # Defining the subfunction\n",
    "    def rmse_per(predictions, targets):\n",
    "        targets=targets+0.000001\n",
    "        percentage_error=(np.abs(predictions-targets)/targets)*100\n",
    "        RMSEValue=np.sqrt(((predictions - targets) ** 2).mean())\n",
    "        return RMSEValue,percentage_error\n",
    "\n",
    "    changepoint_prior_scale= [0.001, 0.01, 0.05, 0.1, 0.5]\n",
    "    seasonality_prior_scale= [0.01, 0.05, 0.1, 0.5 ,1.0, 5,10.0]\n",
    "    seasonality_mode=['additive', 'multiplicative']\n",
    "    changepoint_range= [0.8, 0.85, 0.9, 0.95]\n",
    "    cnt=0\n",
    "    Result_hyperParameter_tuning=pd.DataFrame()\n",
    "    for k1 in changepoint_range:\n",
    "        for k in seasonality_mode:\n",
    "            for i in changepoint_prior_scale:\n",
    "                for j in seasonality_prior_scale:\n",
    "                    modeltest = Prophet(seasonality_mode=k,changepoint_prior_scale=i,seasonality_prior_scale=j,changepoint_range=k1)                    \n",
    "                    if Database=='Practice_CAI':\n",
    "                        modeltest.add_regressor('add1')\n",
    "                        modeltest.add_regressor('add2')\n",
    "                        modeltest.add_regressor('add3')\n",
    "                        modeltest.add_regressor('add4')\n",
    "                        modeltest.add_regressor('add5')\n",
    "                        modeltest.add_regressor('add6')\n",
    "                        modeltest.add_regressor('add7')\n",
    "                        modeltest.add_regressor('add8')\n",
    "                        modeltest.add_regressor('add9') \n",
    "                    elif Database=='Practice_DA':\n",
    "                        modeltest.add_regressor('add1')\n",
    "                        modeltest.add_regressor('add2')\n",
    "                        modeltest.add_regressor('add3')\n",
    "                        modeltest.add_regressor('add4')\n",
    "                        modeltest.add_regressor('add5')\n",
    "                        modeltest.add_regressor('add6')\n",
    "                        modeltest.add_regressor('add7')\n",
    "                    elif Database=='Region_USEast':\n",
    "                        modeltest.add_regressor('add1')\n",
    "                        modeltest.add_regressor('add2')\n",
    "                        modeltest.add_regressor('add3')\n",
    "                        modeltest.add_regressor('add4')\n",
    "                        modeltest.add_regressor('add5')\n",
    "                        modeltest.add_regressor('add6')\n",
    "                        modeltest.add_regressor('add7')                        \n",
    "                    elif Database=='Region_USWest':\n",
    "                        modeltest.add_regressor('add1')\n",
    "                        modeltest.add_regressor('add2')\n",
    "                        modeltest.add_regressor('add3')\n",
    "                        modeltest.add_regressor('add4')\n",
    "                        modeltest.add_regressor('add5')\n",
    "                        modeltest.add_regressor('add6')\n",
    "                        modeltest.add_regressor('add7')\n",
    "                    elif Database=='BFSI_DIR':\n",
    "                        modeltest.add_regressor('add1')\n",
    "                        modeltest.add_regressor('add2')\n",
    "                        modeltest.add_regressor('add3')\n",
    "                        modeltest.add_regressor('add4')\n",
    "                        modeltest.add_regressor('add5')\n",
    "                        modeltest.add_regressor('add6')\n",
    "                    elif Database=='Region_USCentral':\n",
    "                        modeltest.add_regressor('add1')\n",
    "                        modeltest.add_regressor('add2')\n",
    "                        modeltest.add_regressor('add3')\n",
    "                        modeltest.add_regressor('add4')\n",
    "                        modeltest.add_regressor('add5')\n",
    "                    elif Database=='BFSI_AWS':\n",
    "                        modeltest.add_regressor('add1')\n",
    "                        modeltest.add_regressor('add2')\n",
    "                        modeltest.add_regressor('add3')\n",
    "                        modeltest.add_regressor('add4')\n",
    "                        modeltest.add_regressor('add5')\n",
    "                    elif Database=='BFSI_GCP':\n",
    "                        modeltest.add_regressor('add1')\n",
    "                        modeltest.add_regressor('add2')\n",
    "                        modeltest.add_regressor('add3')\n",
    "                        modeltest.add_regressor('add4')\n",
    "                    \n",
    "                    modeltest.fit(X_train)\n",
    "                    forecast_val = modeltest.predict(X_val.drop(columns=\"y\"))\n",
    "                    A, per_error=rmse_per(np.array(forecast_val['yhat']), np.array(X_val['y']))\n",
    "\n",
    "                    forecast_train = modeltest.predict(X_train.drop(columns=\"y\"))\n",
    "                    A, per_error_train=rmse_per(np.array(forecast_train['yhat']), np.array(X_train['y']))\n",
    "\n",
    "                    dftemp = {'MAPE Val': per_error.mean(),'MAPE Train': per_error_train.mean(),'RMSE':A,'Absolute Error': abs(np.array(forecast_val['yhat'])-np.array(X_val['y'])), 'seasonality_prior_scale': j,'changepoint_prior_scale': i,'seasonality_mode':k,'changepoint_range':k1}\n",
    "                    Result_hyperParameter_tuning = Result_hyperParameter_tuning.append(dftemp, ignore_index = True)\n",
    "                    \n",
    "    Result_hyperParameter_tuning['MAPE Val']=Result_hyperParameter_tuning['MAPE Val'].astype('float64')\n",
    "    minValueLoc = Result_hyperParameter_tuning['MAPE Val'].idxmin()\n",
    "    HP=Result_hyperParameter_tuning.iloc[minValueLoc,:]                # Considering hyper parameter for which MSPE is less on validation set \n",
    "    HP.changepoint_prior_scale\n",
    "    HP.changepoint_range\n",
    "    HP.seasonality_mode\n",
    "    HP.seasonality_prior_scale\n",
    "\n",
    "    #---------------UPDATING WITH BEST PARAMETER HERE ---------------------\n",
    "    # Training the model with the best Hyper parameters\n",
    "    modeltest = Prophet(seasonality_mode=HP.seasonality_mode,changepoint_prior_scale=HP.changepoint_prior_scale,seasonality_prior_scale=HP.seasonality_prior_scale,changepoint_range=HP.changepoint_range)\n",
    "    if Database=='Practice_CAI':\n",
    "        modeltest.add_regressor('add1')\n",
    "        modeltest.add_regressor('add2')\n",
    "        modeltest.add_regressor('add3')\n",
    "        modeltest.add_regressor('add4')\n",
    "        modeltest.add_regressor('add5')\n",
    "        modeltest.add_regressor('add6')\n",
    "        modeltest.add_regressor('add7')\n",
    "        modeltest.add_regressor('add8')\n",
    "        modeltest.add_regressor('add9') \n",
    "    elif Database=='Practice_DA':\n",
    "        modeltest.add_regressor('add1')\n",
    "        modeltest.add_regressor('add2')\n",
    "        modeltest.add_regressor('add3')\n",
    "        modeltest.add_regressor('add4')\n",
    "        modeltest.add_regressor('add5')\n",
    "        modeltest.add_regressor('add6')\n",
    "        modeltest.add_regressor('add7')\n",
    "    elif Database=='Region_USEast':\n",
    "        modeltest.add_regressor('add1')\n",
    "        modeltest.add_regressor('add2')\n",
    "        modeltest.add_regressor('add3')\n",
    "        modeltest.add_regressor('add4')\n",
    "        modeltest.add_regressor('add5')\n",
    "        modeltest.add_regressor('add6')\n",
    "        modeltest.add_regressor('add7')                        \n",
    "    elif Database=='Region_USWest':\n",
    "        modeltest.add_regressor('add1')\n",
    "        modeltest.add_regressor('add2')\n",
    "        modeltest.add_regressor('add3')\n",
    "        modeltest.add_regressor('add4')\n",
    "        modeltest.add_regressor('add5')\n",
    "        modeltest.add_regressor('add6')\n",
    "        modeltest.add_regressor('add7')\n",
    "    elif Database=='BFSI_DIR':\n",
    "        modeltest.add_regressor('add1')\n",
    "        modeltest.add_regressor('add2')\n",
    "        modeltest.add_regressor('add3')\n",
    "        modeltest.add_regressor('add4')\n",
    "        modeltest.add_regressor('add5')\n",
    "        modeltest.add_regressor('add6')\n",
    "    elif Database=='Region_USCentral':\n",
    "        modeltest.add_regressor('add1')\n",
    "        modeltest.add_regressor('add2')\n",
    "        modeltest.add_regressor('add3')\n",
    "        modeltest.add_regressor('add4')\n",
    "        modeltest.add_regressor('add5')\n",
    "    elif Database=='BFSI_AWS':\n",
    "        modeltest.add_regressor('add1')\n",
    "        modeltest.add_regressor('add2')\n",
    "        modeltest.add_regressor('add3')\n",
    "        modeltest.add_regressor('add4')\n",
    "        modeltest.add_regressor('add5')\n",
    "    elif Database=='BFSI_GCP':\n",
    "        modeltest.add_regressor('add1')\n",
    "        modeltest.add_regressor('add2')\n",
    "        modeltest.add_regressor('add3')\n",
    "        modeltest.add_regressor('add4')\n",
    "    modeltest.fit(X_train)\n",
    "    return modeltest    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36094e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### HyperParameter tuning for FBProphet-L0,L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd40e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defined for hyperparameter tuning the L0-level and L1-level\n",
    "def hyperParameter_tuning_L0_L1(X_train,X_val):\n",
    "    # Defining the subfunction\n",
    "    def rmse_per(predictions, targets):\n",
    "\n",
    "        targets=targets+0.000001\n",
    "        percentage_error=(np.abs(predictions-targets)/targets)*100\n",
    "        RMSEValue=np.sqrt(((predictions - targets) ** 2).mean())\n",
    "        return RMSEValue,percentage_error\n",
    "\n",
    "    changepoint_prior_scale= [0.001, 0.01, 0.05, 0.1, 0.5]\n",
    "    seasonality_prior_scale= [0.01, 0.05, 0.1, 0.5 ,1.0, 5,10.0]\n",
    "    seasonality_mode=['additive', 'multiplicative']\n",
    "    changepoint_range= [0.8, 0.85, 0.9, 0.95]\n",
    "    cnt=0\n",
    "    Result_hyperParameter_tuning=pd.DataFrame()\n",
    "    for k1 in changepoint_range:\n",
    "        for k in seasonality_mode:\n",
    "            for i in changepoint_prior_scale:\n",
    "                for j in seasonality_prior_scale:\n",
    "                    modeltest = Prophet(seasonality_mode=k,changepoint_prior_scale=i,seasonality_prior_scale=j,changepoint_range=k1)\n",
    "                    modeltest.add_regressor('add1')\n",
    "                    modeltest.add_regressor('add2')\n",
    "                    modeltest.add_regressor('add3')\n",
    "                    modeltest.add_regressor('add4')\n",
    "                    modeltest.add_regressor('add5')\n",
    "                    modeltest.add_regressor('add6')\n",
    "                    modeltest.add_regressor('add7')\n",
    "                    modeltest.add_regressor('add8')\n",
    "                    modeltest.add_regressor('add9')\n",
    "                    modeltest.fit(X_train)\n",
    "                    forecast_val = modeltest.predict(X_val.drop(columns=\"y\"))\n",
    "                    A, per_error=rmse_per(np.array(forecast_val['yhat']), np.array(X_val['y']))\n",
    "\n",
    "                    forecast_train = modeltest.predict(X_train.drop(columns=\"y\"))\n",
    "                    A, per_error_train=rmse_per(np.array(forecast_train['yhat']), np.array(X_train['y']))\n",
    "\n",
    "                    dftemp = {'MAPE Val': per_error.mean(),'MAPE Train': per_error_train.mean(),'RMSE':A,'Absolute Error': abs(np.array(forecast_val['yhat'])-np.array(X_val['y'])), 'seasonality_prior_scale': j,'changepoint_prior_scale': i,'seasonality_mode':k,'changepoint_range':k1}\n",
    "                    Result_hyperParameter_tuning = Result_hyperParameter_tuning.append(dftemp, ignore_index = True)\n",
    "                    \n",
    "    Result_hyperParameter_tuning['MAPE Val']=Result_hyperParameter_tuning['MAPE Val'].astype('float64')\n",
    "    minValueLoc = Result_hyperParameter_tuning['MAPE Val'].idxmin()\n",
    "    HP=Result_hyperParameter_tuning.iloc[minValueLoc,:]\n",
    "    HP.changepoint_prior_scale\n",
    "    HP.changepoint_range\n",
    "    HP.seasonality_mode\n",
    "    HP.seasonality_prior_scale\n",
    "  #  ---------------UPDATE WITH BEST PARAMETER HERE ---------------------\n",
    "    # Training the model with the best Hyper parameters\n",
    "    modelL0 = Prophet(seasonality_mode=HP.seasonality_mode,changepoint_prior_scale=HP.changepoint_prior_scale,seasonality_prior_scale=HP.seasonality_prior_scale,changepoint_range=HP.changepoint_range)\n",
    "    modelL0.add_regressor('add1')\n",
    "    modelL0.add_regressor('add2')\n",
    "    modelL0.add_regressor('add3')\n",
    "    modelL0.add_regressor('add4')\n",
    "    modelL0.add_regressor('add5')\n",
    "    modelL0.add_regressor('add6')\n",
    "    modelL0.add_regressor('add7')\n",
    "    modelL0.add_regressor('add8')\n",
    "    modelL0.add_regressor('add9')\n",
    "    modelL0.fit(X_train)\n",
    "    return modelL0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to load and save the model in pckl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function that is used to load the trained models in pckl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f082f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  SubFunction Declration (FBProphet)\n",
    "# loading L1-Level model # \n",
    "def loadingL1_Model_pcklfile():\n",
    "    with open('model_FBProphet_L1_GCP.pckl', 'rb') as fin:\n",
    "        model_L1_GCP = pickle.load(fin)\n",
    "    with open('model_FBProphet_L1_AWS.pckl', 'rb') as fin:\n",
    "        model_L1_AWS = pickle.load(fin)\n",
    "    with open('model_FBProphet_L1_BFSI.pckl', 'rb') as fin:\n",
    "        model_L1_BFSI = pickle.load(fin)\n",
    "    with open('model_FBProphet_L1_HCLS.pckl', 'rb') as fin:\n",
    "        model_L1_HCLS = pickle.load(fin)\n",
    "    with open('model_FBProphet_L1_TMEG.pckl', 'rb') as fin:\n",
    "        model_L1_TMEG = pickle.load(fin)\n",
    "    return model_L1_GCP,model_L1_AWS,model_L1_BFSI,model_L1_HCLS,model_L1_TMEG\n",
    "    \n",
    "# loading L2-Level model #\n",
    "def loadingL2_Model_pcklfile():\n",
    "    with open('model_FBProphet_L2_BFSI_GCP.pckl', 'rb') as fin:\n",
    "        model_L2_BFSI_GCP = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_BFSI_AWS.pckl', 'rb') as fin:\n",
    "        model_L2_BFSI_AWS = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_BFSI_DIR.pckl', 'rb') as fin:\n",
    "        model_L2_BFSI_DIR = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_GCP_Region_USEast.pckl', 'rb') as fin:\n",
    "        model_L2_Region_USEast = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_GCP_Region_USWest.pckl', 'rb') as fin:\n",
    "        model_L2_Region_USWest = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_GCP_Region_USCentral.pckl', 'rb') as fin:\n",
    "        model_L2_Region_USCentral = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_GCP_Practice_DA.pckl', 'rb') as fin:\n",
    "        model_L2_Practice_DA = pickle.load(fin)\n",
    "    with open('model_FBProphet_L2_GCP_Practice_CAI.pckl', 'rb') as fin:\n",
    "        model_L2_Practice_CAI = pickle.load(fin)\n",
    "    return model_L2_BFSI_GCP,model_L2_BFSI_AWS,model_L2_BFSI_DIR,model_L2_Region_USCentral,model_L2_Region_USEast,model_L2_Region_USWest,model_L2_Practice_CAI,model_L2_Practice_DA    \n",
    "# Loading L0-Level model\n",
    "def loadingL0_Model_pcklfile():\n",
    "    with open('model_FBProphet_L0.pckl', 'rb') as fin:\n",
    "        model_L0 = pickle.load(fin)\n",
    "    return model_L0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e0ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function to save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7546a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this section Newly trained model will be saved\n",
    "# Model saving at L0-level\n",
    "def save_training_model_L0(Model_L0):\n",
    "  model_FBProphet_L0=Model_L0  \n",
    "  with open('model_FBProphet_L0.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L0, fout)\n",
    "\n",
    "# Model saving at L1-level\n",
    "def save_training_model_L1(Model_L1_GCP,Model_L1_AWS,Model_L1_BFSI,Model_L1_HCLS,Model_L1_TMEG):\n",
    "  model_FBProphet_L1_GCP=Model_L1_GCP  \n",
    "  with open('model_FBProphet_L1_GCP.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L1_GCP, fout)\n",
    "  \n",
    "  model_FBProphet_L1_AWS=Model_L1_AWS  \n",
    "  with open('model_FBProphet_L1_AWS.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L1_AWS, fout)\n",
    "\n",
    "  model_FBProphet_L1_BFSI=Model_L1_BFSI  \n",
    "  with open('model_FBProphet_L1_BFSI.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L1_BFSI, fout)\n",
    "\n",
    "  model_FBProphet_L1_HCLS=Model_L1_HCLS  \n",
    "  with open('model_FBProphet_L1_HCLS.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L1_HCLS, fout)\n",
    "\n",
    "  model_FBProphet_L1_TMEG=Model_L1_TMEG  \n",
    "  with open('model_FBProphet_L1_TMEG.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L1_TMEG, fout)\n",
    "\n",
    "# Model saving at L2-level\n",
    "def save_training_model_L2(Model_L2_BFSI_GCP,Model_L2_BFSI_AWS,Model_L2_BFSI_DIR,Model_L2_Region_USEast,Model_L2_Region_USWest,Model_L2_Region_USCentral,Model_L2_Practice_DA,Model_L2_Practice_CAI):\n",
    "  model_FBProphet_L2_BFSI_GCP=Model_L2_BFSI_GCP  \n",
    "  with open('model_FBProphet_L2_BFSI_GCP.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L2_BFSI_GCP, fout)\n",
    "\n",
    "  model_FBProphet_L2_BFSI_AWS=Model_L2_BFSI_AWS  \n",
    "  with open('model_FBProphet_L2_BFSI_AWS.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L2_BFSI_AWS, fout)\n",
    "\n",
    "  model_FBProphet_L2_BFSI_DIR=Model_L2_BFSI_DIR  \n",
    "  with open('model_FBProphet_L2_BFSI_DIR.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L2_BFSI_DIR, fout)\n",
    "\n",
    "  model_FBProphet_L2_GCP_Region_USEast=Model_L2_Region_USEast  \n",
    "  with open('model_FBProphet_L2_GCP_Region_USEast.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L2_GCP_Region_USEast, fout)\n",
    "\n",
    "  model_FBProphet_L2_GCP_Region_USWest=Model_L2_Region_USWest  \n",
    "  with open('model_FBProphet_L2_GCP_Region_USWest.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L2_GCP_Region_USWest, fout)\n",
    "\n",
    "  model_FBProphet_L2_GCP_Region_USCentral=Model_L2_Region_USCentral  \n",
    "  with open('model_FBProphet_L2_GCP_Region_USCentral.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L2_GCP_Region_USCentral, fout)    \n",
    "\n",
    "  model_FBProphet_L2_GCP_Practice_DA=Model_L2_Practice_DA  \n",
    "  with open('model_FBProphet_L2_GCP_Practice_DA.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L2_GCP_Practice_DA, fout)\n",
    "\n",
    "  model_FBProphet_L2_GCP_Practice_CAI=Model_L2_Practice_CAI  \n",
    "  with open('model_FBProphet_L2_GCP_Practice_CAI.pckl', 'wb') as fout:\n",
    "    pickle.dump(model_FBProphet_L2_GCP_Practice_CAI, fout) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c31562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function written for training the FBProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd6d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model training for FBProphet\n",
    "#### Given the data and number of validation month information. The function will return the trained model and the MAPE\n",
    "## L0,L1-level model\n",
    "def rmse_per(predictions, targets):\n",
    "\n",
    "    targets=targets+0.000001\n",
    "    percentage_error=(np.abs(predictions-targets)/targets)*100\n",
    "    RMSEValue=np.sqrt(((predictions - targets) ** 2).mean())\n",
    "    return RMSEValue,percentage_error\n",
    "\n",
    "def training_L0_L1_model_FBProphet(L0_Data,num_Val=2):\n",
    "    L0_Data1=modelLevel_Preprocessing(L0_Data,case='train')\n",
    "    L0_Data2=featureArrangeL0_L1(L0_Data1,case='train')\n",
    "    \n",
    "    num_months_validation=num_Val\n",
    "    X_train =L0_Data2.loc[0:(L0_Data2.shape[0]-(num_months_validation+1))]\n",
    "    X_val  = L0_Data2.loc[(L0_Data2.shape[0]-num_months_validation):L0_Data2.shape[0]]\n",
    "    X_val.reset_index(inplace=True,drop=True)\n",
    "    modelL0=hyperParameter_tuning_L0_L1(X_train,X_val)\n",
    "    \n",
    "    forecast_val = modelL0.predict(X_val.drop(columns=\"y\"))\n",
    "    df_Result_Val=pd.DataFrame({'actual': X_val.y.values, 'predicted': forecast_val.yhat.values.astype(int)})\n",
    "    df_Result_Val.insert(loc=0, column='Date', value=X_val.ds.values)\n",
    "    A, per_error=rmse_per(np.array(forecast_val['yhat']), np.array(X_val['y']))\n",
    "    df_Result_Val['Absolute Error']=abs(np.array(forecast_val['yhat'])-np.array(X_val['y']))\n",
    "    df_Result_Val['Percentage Error']=per_error\n",
    "    df_Result_Val.reset_index(drop=True, inplace=True)\n",
    "#    mape_val=per_error.mean()\n",
    "    return modelL0,df_Result_Val\n",
    "## L2-level model\n",
    "def training_L2_model_FBProphet(L2_Data,num_Val=2,Database='BFSI_GCP'):\n",
    "    L2_Data1=modelLevel_Preprocessing(L2_Data,case='train')\n",
    "    L2_Data2=featureArrangeL2(L2_Data1,Database,case='train') \n",
    "    num_months_validation=num_Val\n",
    "    X_train =L2_Data2.loc[0:(L2_Data2.shape[0]-(num_months_validation+1))]\n",
    "    X_val  = L2_Data2.loc[(L2_Data2.shape[0]-num_months_validation):L2_Data2.shape[0]]\n",
    "    X_val.reset_index(inplace=True,drop=True)\n",
    "    modelL2=hyperParameter_tuning_L2(X_train,X_val,Database)\n",
    "    forecast_val = modelL2.predict(X_val.drop(columns=\"y\"))\n",
    "    df_Result_Val=pd.DataFrame({'actual': X_val.y.values, 'predicted': forecast_val.yhat.values.astype(int)})\n",
    "    df_Result_Val.insert(loc=0, column='Date', value=X_val.ds.values)\n",
    "    A, per_error=rmse_per(np.array(forecast_val['yhat']), np.array(X_val['y']))\n",
    "    df_Result_Val['Absolute Error']=abs(np.array(forecast_val['yhat'])-np.array(X_val['y']))\n",
    "    df_Result_Val['Percentage Error']=per_error\n",
    "    df_Result_Val.reset_index(drop=True, inplace=True)\n",
    "#    mape_val=per_error.mean()\n",
    "    return modelL2,df_Result_Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d821b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################  Function Declared for FBProphet End here ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c10bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbf3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_per_training(button):\n",
    "    with output_box:\n",
    "        ################Training section note book is written here\n",
    "        ############################################### This Flow is for Training Section ##############################################\n",
    "        ########################################### Training and Test data will be loaded here #########################################\n",
    "        ################################################################################################################################\n",
    "\n",
    "        Label1=widgets.Label(\"Please upload the recent 'PD SYNC' file in .csv or .xlsx format\")\n",
    "        uploader_df1 = widgets.FileUpload(#accept='*.xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "            multiple=False)  # True to accept multiple files upload else False)\n",
    "\n",
    "        #display(uploader_df1.value) \n",
    "\n",
    "        get_data_button = widgets.Button(description='Next',button_style='info',tooltip='Loads the PD sync data')\n",
    "\n",
    "\n",
    "        def get_data(b):\n",
    "            input_file = list(uploader_df1.value.values())[0]\n",
    "            content = input_file['content']\n",
    "            #content = io.StringIO(content.decode('utf-8'))\n",
    "\n",
    "            input_file_Name=input_file['metadata']['name']\n",
    "            File_name_temp1=input_file_Name.split('.')\n",
    "            File_type=File_name_temp1[1]\n",
    "            if File_type=='csv':\n",
    "                df1 = pd.read_csv(input_file_Name)\n",
    "            else:\n",
    "                df1 = pd.read_excel(content)\n",
    "\n",
    "            get_data.data=df1\n",
    "            return get_data.data\n",
    "\n",
    "        ###### B22\n",
    "        #print('Please upload PDSync test data in .csv / .xlsx format to generate predictions')\n",
    "\n",
    "        Label2Train=widgets.Label(\"Please upload the 'Rev Projection Training sheet' file in .csv or .xlsx format\")\n",
    "        uploader_df2Train = widgets.FileUpload(#accept='*.xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "            multiple=False)  # True to accept multiple files upload else False)\n",
    "\n",
    "        #display(uploader_df2Train.value) \n",
    "\n",
    "        get_data_button2Train = widgets.Button(description='Next',button_style='info',tooltip='Loads the Rev Projection data for Training')\n",
    "\n",
    "        def get_datadf2Train(b):\n",
    "            input_file = list(uploader_df2Train.value.values())[0]\n",
    "            content = input_file['content']\n",
    "            #content = io.StringIO(content.decode('utf-8'))\n",
    "\n",
    "            input_file_Name=input_file['metadata']['name']\n",
    "            File_name_temp1=input_file_Name.split('.')\n",
    "            File_type=File_name_temp1[1]\n",
    "            if File_type=='csv':\n",
    "                df2 = pd.read_csv(input_file_Name)\n",
    "            else:\n",
    "                df2 = pd.read_excel(content)\n",
    "            get_datadf2Train.data=df2\n",
    "\n",
    "            return get_datadf2Train.data\n",
    "\n",
    "\n",
    "        ###### B13\n",
    "        get_data_button2 = widgets.Button(description='Next',button_style='info',tooltip='Loads the Rev Projection test data')\n",
    "\n",
    "        Label2=widgets.Label(f'Please upload the \"Rev Projection Test sheet\" in .csv or .xlsx format. For which you want the prediction for')\n",
    "\n",
    "        uploader_df2 = widgets.FileUpload(\n",
    "            #accept='*.xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "            multiple=True  # True to accept multiple files upload else False\n",
    "        )\n",
    "        #uploader_df2\n",
    "        def get_datadf2(b):\n",
    "            A=[]\n",
    "            df2 = pd.DataFrame()\n",
    "            for i in range(len(uploader_df2.value.values())):\n",
    "                input_file = list(uploader_df2.value.values())[i]\n",
    "                #print(input_file['metadata']['name'])\n",
    "                A.append(input_file['metadata']['name'])\n",
    "                content = input_file['content']\n",
    "\n",
    "                input_file_Name=input_file['metadata']['name']\n",
    "                File_name_temp1=input_file_Name.split('.')\n",
    "                File_type=File_name_temp1[1]\n",
    "                if File_type=='csv':\n",
    "                    df2_temp = pd.read_csv(input_file_Name)\n",
    "                else:\n",
    "                    df2_temp = pd.read_excel(content)\n",
    "\n",
    "                # This section will extract the month and year information from the file name\n",
    "                File_name=input_file['metadata']['name']\n",
    "                File_name_temp1=File_name.split('.')\n",
    "                File_name_temp2=File_name_temp1[0]\n",
    "                File_name_temp2=File_name_temp2.split('_')\n",
    "                year_info=File_name_temp2[len(File_name_temp2)-1]\n",
    "                month_info=File_name_temp2[len(File_name_temp2)-2]\n",
    "\n",
    "                df2_temp.insert(loc=0, column='Month', value=int(month_info))\n",
    "                df2_temp.insert(loc=0, column='Year', value=int(year_info))\n",
    "\n",
    "                df2=df2.append(df2_temp, ignore_index=True)\n",
    "            get_datadf2.data=df2      \n",
    "            return get_datadf2.data   \n",
    "\n",
    "        # DISPLAY BUTTON\n",
    "        get_data_button.on_click(get_data)   \n",
    "        get_data_button2Train.on_click(get_datadf2Train)\n",
    "        get_data_button2.on_click(get_datadf2)\n",
    "\n",
    "        Label_Train_1 = widgets.HTML(value=\"<h3> Please upload the dataset for Training and data for future prediction </h3>\")\n",
    "\n",
    "        left_box1A=widgets.HBox([uploader_df1,get_data_button])\n",
    "        left_box2Train=widgets.HBox([uploader_df2Train,get_data_button2Train])\n",
    "        # left_box1\n",
    "        left_box2A=widgets.HBox([uploader_df2,get_data_button2])\n",
    "        # left_box2\n",
    "        left_boxA=widgets.VBox([Label_Train_1,Label1,left_box1A,Label2Train,left_box2Train,Label2,left_box2A])\n",
    "        #\n",
    "\n",
    "\n",
    "        ############################################## Model Level information is taken  ###############################################\n",
    "        ################################################## model will be trained here ##################################################\n",
    "        ################################################################################################################################\n",
    "\n",
    "        outputlev = widgets.Output()\n",
    "        style = {'description_width': 'initial'}\n",
    "        level_selector = widgets.RadioButtons(\n",
    "                                 options=['L0','L1','L2'],\n",
    "                                 value=None,\n",
    "                                 description='Choose model Level : ',\n",
    "                                 disabled=False,style=style,\n",
    "        #     layout=widgets.Layout(width='100%')\n",
    "        )\n",
    "\n",
    "        Bt0 = widgets.Button(description='Start Training',disabled=False,button_style='info',tooltip='Model will be trained for L0 level', icon='run')\n",
    "        Bt1 = widgets.Button(description='Start Training',disabled=False,button_style='info', tooltip='Model will be trained for L1 level (GCP, AWS, BFSI, HCLS, TMEG)',icon='run')\n",
    "        Bt2 = widgets.Button(description='Start Training',disabled=False,button_style='info', tooltip='Model will be trained for L2 levle (BFSI-GCP, BFSI-AWS, BFSI-Direct, Region-USCentral, Region-USEast, Region-USWest, Practice-GCP-Data Analytics)',icon='run')\n",
    "\n",
    "        def selectlevel(button):\n",
    "            with outputlev:\n",
    "                selection = level_selector.get_interact_value()\n",
    "                if (selection == \"L0\"):\n",
    "                    with outputlev:\n",
    "                        print('Selected the L0-Level for training model')\n",
    "                        display(Validation_months)\n",
    "                        display(Bt0)                 \n",
    "                elif (selection ==\"L1\"):\n",
    "                        print('Selected the L1-Level for training model')\n",
    "        #                level1_selector.observe(on_change1)\n",
    "                        display(Validation_months)\n",
    "                        display(Bt1)\n",
    "\n",
    "                elif (selection ==\"L2\"):\n",
    "                        print('Selected the L2-Level for training model')\n",
    "        #                level2_selector.observe(on_change2)\n",
    "                        display(Validation_months)\n",
    "                        display(Bt2)\n",
    "\n",
    "        def train_model_L0(button):\n",
    "            with outputlev:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2Train.data\n",
    "        #         print('L0 section')\n",
    "        #         print('df1 size=',df1.shape)\n",
    "        #         print('df2 size=',df2.shape)\n",
    "                # model training section\n",
    "                df_L0=dataPrepartaionL0_FbProphet(df1,df2)\n",
    "                number_validation_month=Validation_months.value\n",
    "                Model_L0,MAPE_L0=training_L0_L1_model_FBProphet(df_L0,num_Val=number_validation_month)\n",
    "                save_training_model_L0(Model_L0)\n",
    "                print('Model training is completed for L0-level')\n",
    "                print('Validation result for L0-level')\n",
    "                print(MAPE_L0)\n",
    "        #         Predict_L0,date_ref=L0_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "        #         df = pd.DataFrame()\n",
    "        #         df['Date']=date_ref['ds']\n",
    "        #         df['Prediction']=Predict_L0\n",
    "        #         print('Prediction for L0-level')\n",
    "        #         print(df)\n",
    "\n",
    "        def train_model_L1(button):\n",
    "            with outputlev:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2Train.data\n",
    "                temp1,temp2,temp3,temp4,temp5,RF_V2_GCP,RF_V2_AWS,RF_V2_BFSI,RF_V2_HCLS,RF_V2_TMEG=dataPrepartaionL1(df1,df2)\n",
    "                number_validation_month=Validation_months.value\n",
    "                Model_L1_GCP,MAPE_L1_GCP=training_L0_L1_model_FBProphet(RF_V2_GCP,num_Val=number_validation_month)\n",
    "                Model_L1_AWS,MAPE_L1_AWS=training_L0_L1_model_FBProphet(RF_V2_AWS,num_Val=number_validation_month)\n",
    "                Model_L1_BFSI,MAPE_L1_BFSI=training_L0_L1_model_FBProphet(RF_V2_BFSI,num_Val=number_validation_month)\n",
    "                Model_L1_HCLS,MAPE_L1_HCLS=training_L0_L1_model_FBProphet(RF_V2_HCLS,num_Val=number_validation_month)\n",
    "                Model_L1_TMEG,MAPE_L1_TMEG=training_L0_L1_model_FBProphet(RF_V2_TMEG,num_Val=number_validation_month)\n",
    "                save_training_model_L1(Model_L1_GCP,Model_L1_AWS,Model_L1_BFSI,Model_L1_HCLS,Model_L1_TMEG)\n",
    "                print('Model training is completed for L1-level')\n",
    "                print('Validation result for L1-level')\n",
    "                print('GCP')\n",
    "                print(MAPE_L1_GCP)\n",
    "                print('AWS')\n",
    "                print(MAPE_L1_AWS)\n",
    "                print('BFSI')\n",
    "                print(MAPE_L1_BFSI)\n",
    "                print('HCLS')\n",
    "                print(MAPE_L1_HCLS)\n",
    "                print('TMEG')\n",
    "                print(MAPE_L1_TMEG)        \n",
    "\n",
    "        #         print('df1 size=',df1.shape)\n",
    "        #         print('df2 size=',df2.shape) \n",
    "\n",
    "\n",
    "        #         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "        #         df = pd.DataFrame()\n",
    "        #         df['Date']=date_ref['ds']\n",
    "        #         df['Prediction']=Predict_L1_GCP\n",
    "        #         print('Prediction for L1-level: GCP')\n",
    "        #         print(df)        \n",
    "\n",
    "        def train_model_L2(button):\n",
    "            with outputlev:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2Train.data\n",
    "                number_validation_month=Validation_months.value\n",
    "                df_gcp_USEast,df_gcp_USWest,df_gcp_USCentral,df_gcp_Practice_DA,df_gcp_Practice_CAI,df_bfsi_gcp,df_bfsi_aws,df_bfsi_dir=dataPrepartaionL2_FBProphet(df1,df2)\n",
    "                Model_L2_Region_USEast,MAPE_L2_Region_USEast=training_L2_model_FBProphet(df_gcp_USEast,num_Val=number_validation_month,Database='Region_USEast')\n",
    "                Model_L2_Region_USWest,MAPE_L2_Region_USWest=training_L2_model_FBProphet(df_gcp_USWest,num_Val=number_validation_month,Database='Region_USWest')\n",
    "                Model_L2_Region_USCentral,MAPE_L2_Region_USCentral=training_L2_model_FBProphet(df_gcp_USCentral,num_Val=number_validation_month,Database='Region_USCentral')\n",
    "\n",
    "                Model_L2_Practice_DA,MAPE_L2_Practice_DA=training_L2_model_FBProphet(df_gcp_Practice_DA,num_Val=number_validation_month,Database='Practice_DA')\n",
    "                Model_L2_Practice_CAI,MAPE_L2_Practice_CAI=training_L2_model_FBProphet(df_gcp_Practice_CAI,num_Val=number_validation_month,Database='Practice_CAI')\n",
    "\n",
    "                Model_L2_BFSI_GCP,MAPE_L2_BFSI_GCP=training_L2_model_FBProphet(df_bfsi_gcp,num_Val=number_validation_month,Database='BFSI_GCP')\n",
    "                Model_L2_BFSI_AWS,MAPE_L2_BFSI_AWS=training_L2_model_FBProphet(df_bfsi_aws,num_Val=number_validation_month,Database='BFSI_AWS')\n",
    "                Model_L2_BFSI_DIR,MAPE_L2_BFSI_DIR=training_L2_model_FBProphet(df_bfsi_dir,num_Val=number_validation_month,Database='BFSI_DIR')\n",
    "\n",
    "                save_training_model_L2(Model_L2_BFSI_GCP,Model_L2_BFSI_AWS,Model_L2_BFSI_DIR,Model_L2_Region_USEast,Model_L2_Region_USWest,Model_L2_Region_USCentral,Model_L2_Practice_DA,Model_L2_Practice_CAI)        \n",
    "                print('Model training is completed for L2-level')\n",
    "                print('Validation result for L2-level')\n",
    "                print('BFSI-GCP')\n",
    "                print(MAPE_L2_BFSI_GCP)\n",
    "                print('BFSI-AWS')\n",
    "                print(MAPE_L2_BFSI_AWS)\n",
    "                print('BFSI-Direct')\n",
    "                print(MAPE_L2_BFSI_DIR)\n",
    "                print('GCP-Region-USEast')\n",
    "                print(MAPE_L2_Region_USEast)\n",
    "                print('GCP-Region-USWest')\n",
    "                print(MAPE_L2_Region_USWest) \n",
    "                print('GCP-Region-USCentral')\n",
    "                print(MAPE_L2_Region_USCentral)         \n",
    "                print('GCP-Practice-Conversational AI')\n",
    "                print(MAPE_L2_Practice_CAI) \n",
    "                print('GCP-Practice- Data Analytics')\n",
    "                print(MAPE_L2_Practice_DA)\n",
    "\n",
    "        #         print('L2 section')\n",
    "        #         print('df1 size=',df1.shape)\n",
    "        #         print('df2 size=',df2.shape)        \n",
    "        #         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "        #         df = pd.DataFrame()\n",
    "        #         df['Date']=date_ref['ds']\n",
    "        #         df['Prediction']=bfsi_GCP\n",
    "        #         print('Prediction for L2-level: BFSI-GCP')\n",
    "        #         print(df)\n",
    "\n",
    "        lev_button = widgets.Button(\n",
    "        description='Next',\n",
    "        disabled=False,\n",
    "        button_style='info', \n",
    "        tooltip='Confirm the model level selection'\n",
    "        )\n",
    "\n",
    "        lev_button.on_click(selectlevel)\n",
    "        Bt0.on_click(train_model_L0)\n",
    "        Bt1.on_click(train_model_L1)\n",
    "        Bt2.on_click(train_model_L2)\n",
    "\n",
    "        style = {'description_width': 'initial'}\n",
    "        Validation_months=widgets.BoundedIntText(\n",
    "            value=2,\n",
    "            min=0,\n",
    "            max=10,\n",
    "            step=1,\n",
    "            description='Choose num of Validation months:',\n",
    "            disabled=False, style=style\n",
    "        )\n",
    "\n",
    "        Label_Train_21=widgets.HTML(value=\"<h2> Select level of training/ tesing</h2>\")\n",
    "        Label_Train_22=widgets.HTML(value=\"<h3> What are Levels? </h3>\")\n",
    "        Label_Train_23=widgets.HTML(value=\"<h3> There are 3 levels within which the model can generate predictions. These are - L0, L1 and L2. </h3>\")\n",
    "        Label_Train_24=widgets.HTML(value=\"<h3> L0 - For predictions at Quantiphi level </h3>\")\n",
    "        Label_Train_25=widgets.HTML(value=\"<h3> L1 - For predictions at Channel vs. BU level </h3>\")\n",
    "        Label_Train_26=widgets.HTML(value=\"<h3> L2 - For further prediction within a Channel and BU . In channels, only GCP has been considered for prediction due to sufficient data volume. Within GCP predictions can be made for different regions & practices. </h3>\")\n",
    "        Label_Train_27=widgets.HTML(value=\"<h3> IN BUs, only BFSI has been considered for predictions due to sufficient data volume. Within BFSI, prediction can be made for deals that are in AWS, GCP and Direct </h3>\")\n",
    "#        Label_Train_28=widgets.HTML(value=\"<h4> Note: For demo purpose the hyperparameter length is reduced </h4>\")\n",
    "\n",
    "        label_boxB=widgets.VBox([Label_Train_21,Label_Train_22,Label_Train_23,Label_Train_24,Label_Train_25,Label_Train_26,Label_Train_27]) #,Label_Train_28\n",
    "        left_box1B = widgets.HBox([level_selector, lev_button])\n",
    "        #left_box2 = widgets.HBox([Validation_months, outputlev])\n",
    "        left_box3B = widgets.VBox([left_boxA,label_boxB,left_box1B,outputlev])\n",
    "        #left_box3\n",
    "\n",
    "        # left_box1=widgets.HBox([uploader_df1,get_data_button])\n",
    "        # left_box2Train=widgets.HBox([uploader_df2Train,get_data_button2Train])\n",
    "        # # left_box1\n",
    "        # left_box2=widgets.HBox([uploader_df2,get_data_button2])\n",
    "        # # left_box2\n",
    "        # left_box=widgets.VBox([Label1,left_box1,Label2Train,left_box2Train,Label2,left_box2])\n",
    "        # left_box\n",
    "\n",
    "\n",
    "        ####################################### Newly trained Model will be tested here  ##############################################\n",
    "        ########################################### Prediction result will be given ###################################################\n",
    "        ###############################################################################################################################\n",
    "\n",
    "        outputlev1 = widgets.Output()\n",
    "\n",
    "        level1_selector = widgets.RadioButtons(\n",
    "                                 options=['GCP','AWS','BFSI', 'TMEG', 'HCLS'],\n",
    "                                 value=None,\n",
    "                                 description='Select Level: ',\n",
    "                                 disabled=False,\n",
    "        #     layout=widgets.Layout(width='100%')\n",
    "        )\n",
    "\n",
    "        level2_selector = widgets.RadioButtons(\n",
    "                                 options=['BFSI-AWS', 'BFSI-Direct', 'BFSI-GCP', 'Region-USCentral','Region-USEast','Region-USWest'],\n",
    "                                 value=None,\n",
    "                                 description='Select Level: ',\n",
    "                                 disabled=False,\n",
    "        )\n",
    "        B = widgets.Button(\n",
    "         description='Format Data',\n",
    "         disabled=False,\n",
    "         button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "         tooltip='Click me',\n",
    "         icon='run'\n",
    "        )\n",
    "        style = {'description_width': 'initial'}\n",
    "        B0 = widgets.Button(\n",
    "         description='Format Data and predict',\n",
    "         disabled=False,\n",
    "         button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "         tooltip='Click for Format Data and predict',\n",
    "         icon='run',style=style\n",
    "        )\n",
    "\n",
    "        B11 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B12 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B13 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B14 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B15 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "\n",
    "        B21 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B22 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B23 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B24 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B25 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B26 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "\n",
    "        def on_change1(change):\n",
    "            with outputlev:\n",
    "                if change['type'] == 'change' and change['name'] == 'value':\n",
    "                    if change['new'] == 'GCP':\n",
    "                        with outputlev1:\n",
    "                            print('GCP Selected')\n",
    "                            display(B11)\n",
    "                    elif change['new'] == 'BFSI':\n",
    "                        with outputlev1:\n",
    "                            print('BFSI Selected')\n",
    "                            display(B13)\n",
    "                    elif change['new'] == 'AWS':\n",
    "                        with outputlev1:\n",
    "                            print('AWS Selected')  \n",
    "                            display(B12)\n",
    "                    elif change['new'] == 'TMEG':\n",
    "                        with outputlev1:\n",
    "                            print('TMEG Selected')\n",
    "                            display(B15)\n",
    "                    elif change['new'] == 'HCLS':\n",
    "                        with outputlev1:\n",
    "                            print('HCLS Selected')\n",
    "                            display(B14)\n",
    "\n",
    "        def on_change2(change):\n",
    "            with outputlev1:\n",
    "                if change['type'] == 'change' and change['name'] == 'value':\n",
    "                    if change['new'] == 'Region-USCentral':\n",
    "                        with outputlev1:\n",
    "                            print('GCP-Region US Central Selected')\n",
    "                            display(B24)\n",
    "                    elif change['new'] =='Region-USEast':\n",
    "                        with outputlev1:\n",
    "                            print('GCP-Region US East Selected')\n",
    "                            display(B25)\n",
    "                    elif change['new'] =='Region-USWest':\n",
    "                        with outputlev1:\n",
    "                            print('GCP-Region US West Selected')\n",
    "                            display(B26)        \n",
    "                    elif change['new'] =='Practice-CAI':\n",
    "                        with outputlev1:\n",
    "                            print('GCP-Practice-Conversational AI Selected')\n",
    "                            display(B27)                     \n",
    "                    elif change['new'] == 'Practice-DA':\n",
    "                        with outputlev1:\n",
    "                            print('GCP-Practice-Data Analytics Selected')\n",
    "                            display(B28)\n",
    "                    elif change['new'] == 'BFSI-AWS':\n",
    "                        with outputlev1:\n",
    "                            print('BFSI-AWS Selected') \n",
    "                            display(B22)\n",
    "                    elif change['new'] == 'BFSI-Direct':\n",
    "                        with outputlev1:\n",
    "                            print('BFSI-Direct Selected')\n",
    "                            display(B23)\n",
    "                    elif change['new'] == 'BFSI-GCP':\n",
    "                        with outputlev1:\n",
    "                            print('BFSI-GCP Selected')   \n",
    "                            display(B21)\n",
    "\n",
    "        def selectlevel(button):\n",
    "            with outputlev1:\n",
    "                selection = level_selector.get_interact_value()\n",
    "                if (selection == \"L0\"):\n",
    "                    with outputlev1:\n",
    "                        print('L0 Level Selected')\n",
    "                        display(B0)                 \n",
    "                elif (selection ==\"L1\"):\n",
    "                        level1_selector.observe(on_change1)\n",
    "                        display(level1_selector)\n",
    "\n",
    "                elif (selection ==\"L2\"):\n",
    "                        level2_selector.observe(on_change2)\n",
    "                        display(level2_selector)\n",
    "\n",
    "        def prediction_L0(button):\n",
    "            with outputlev1:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L0,date_ref=L0_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L0\n",
    "                print('Prediction for L0-level')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "                \n",
    "        def prediction_L1_GCP(button):\n",
    "            with outputlev1:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L1_GCP\n",
    "                print('Prediction for L1-level: GCP')\n",
    "                print(df)        \n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "        def prediction_L1_AWS(button):\n",
    "            with outputlev1:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L1_AWS\n",
    "                print('Prediction for L1-level: AWS')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "        def prediction_L1_BFSI(button):\n",
    "            with outputlev1:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L1_BFSI\n",
    "                print('Prediction for L1-level: BFSI')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "        def prediction_L1_HCLS(button):\n",
    "            with outputlev1:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L1_HCLS\n",
    "                print('Prediction for L1-level: HCLS')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "        def prediction_L1_TMEG(button):\n",
    "            with outputlev1:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L1_TMEG\n",
    "                print('Prediction for L1-level: TMEG')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "        def prediction_L2_BFSI_GCP(button):\n",
    "            with outputlev1:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=bfsi_GCP\n",
    "                print('Prediction for L2-level: BFSI-GCP')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "        def prediction_L2_BFSI_AWS(button):\n",
    "            with outputlev1:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=bfsi_AWS\n",
    "                print('Prediction for L2-level: BFSI-AWS')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "\n",
    "        def prediction_L2_BFSI_DIR(button):\n",
    "            with outputlev1:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=bfsi_DIR\n",
    "                print('Prediction for L2-level: BFSI-Direct')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "\n",
    "        def prediction_L2_RegionUSCentral(button):\n",
    "            with outputlev1:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=USCentral\n",
    "                print('Prediction for L2-level: Region-US Central')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "\n",
    "        def prediction_L2_RegionUSEast(button):\n",
    "            with outputlev1:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=USEast\n",
    "                print('Prediction for L2-level: Region-US East')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "\n",
    "        def prediction_L2_RegionUSWest(button):\n",
    "            with outputlev1:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=USWest\n",
    "                print('Prediction for L2-level: Region-US West')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "\n",
    "        lev_button1 = widgets.Button(\n",
    "        description='Next',\n",
    "        disabled=False,\n",
    "        button_style='info', \n",
    "        tooltip='click to get prediction for test data'\n",
    "        )\n",
    "\n",
    "        def resultSaveFun(button):\n",
    "            predict_result.to_csv(r'Prediction_Result.csv', index = False)\n",
    "\n",
    "        save_prediction = widgets.Button(description='Save Prediction',disabled=False,button_style='info', tooltip='Predicted result will be saved in CSV file')        \n",
    "        save_prediction.on_click(resultSaveFun)               \n",
    "        \n",
    "        \n",
    "        lev_button1.on_click(selectlevel)\n",
    "        B0.on_click(prediction_L0)\n",
    "        B11.on_click(prediction_L1_GCP)\n",
    "        B12.on_click(prediction_L1_AWS)\n",
    "        B13.on_click(prediction_L1_BFSI)\n",
    "        B14.on_click(prediction_L1_HCLS)\n",
    "        B15.on_click(prediction_L1_TMEG)\n",
    "\n",
    "        B21.on_click(prediction_L2_BFSI_GCP)\n",
    "        B22.on_click(prediction_L2_BFSI_AWS)\n",
    "        B23.on_click(prediction_L2_BFSI_DIR)\n",
    "        B24.on_click(prediction_L2_RegionUSCentral)\n",
    "        B25.on_click(prediction_L2_RegionUSEast)\n",
    "        B26.on_click(prediction_L2_RegionUSWest) \n",
    "\n",
    "        Label_3C = widgets.HTML(value=\"<h2> Prediction using newly trained model</h2>\")\n",
    "        #Label2Train=widgets.Label(\"Please upload the 'Rev Projection Training sheet' file in .csv or .xlsx format\")\n",
    "        left_box5C = widgets.VBox([lev_button1,outputlev1])\n",
    "        l112=widgets.VBox([left_box3B,Label_3C,left_box5C])\n",
    "        display(l112)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600fa0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e4b931b",
   "metadata": {},
   "source": [
    "## FBProphet Model is used to generate predictions\n",
    "**FBprophet is the one of the best model for time series forecasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab182c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_selector = widgets.RadioButtons(\n",
    "#     options=['XGBoost', 'FBProphet'],\n",
    "#     value=None,\n",
    "#     description='Select Model: ',\n",
    "#     disabled=False,\n",
    "# #     layout=widgets.Layout(width='100%')\n",
    "# )\n",
    "# outputmod = widgets.Output()\n",
    "\n",
    "# def selectmodel(button):\n",
    "#     with outputmod:\n",
    "#         selection = model_selector.get_interact_value()\n",
    "\n",
    "#         if (selection == \"XGBoost\"):\n",
    "#     #         existingdata.observe(on_change)\n",
    "#                   with outputmod:\n",
    "#                           print('XGBoost Model Selected')\n",
    "# #                  \n",
    "#         elif (selection ==\"FBProphet\"):\n",
    "#                   with outputmod:\n",
    "#                           print('FBProphet Model Selected')\n",
    "                    \n",
    "# mod_button = widgets.Button(\n",
    "#      description='Next',\n",
    "#      disabled=False,\n",
    "#      button_style='info', \n",
    "#      tooltip='Run'\n",
    "# # #     icon='play'\n",
    "# )\n",
    "# # output_box = widgets.Output()\n",
    "# # # display(my_button, output_box)\n",
    "# mod_button.on_click(selectmodel)\n",
    "# left_box = widgets.VBox([model_selector, mod_button, outputmod])\n",
    "# widgets.HBox([left_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bbd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc4d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_handleingTest_section(button):\n",
    "    with output_box:\n",
    "        ################                           Testing section notebook is written here . This is a consolidate peace of testing\n",
    "        ############################################### This Flow is for Testing Section ##############################################\n",
    "        ########################################### Test data will be loaded here #########################################\n",
    "        ################################################################################################################################\n",
    "        ### B12\n",
    "        #print('Please upload PDSync test data in .csv / .xlsx format to generate predictions')\n",
    "\n",
    "        Label1A=widgets.Label(\"Please upload the recent 'PD SYNC' file in .csv or .xlsx format\")\n",
    "        uploader_df1 = widgets.FileUpload(#accept='*.xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "            multiple=False)  # True to accept multiple files upload else False)\n",
    "\n",
    "        #display(uploader_df1.value) \n",
    "\n",
    "        get_data_button = widgets.Button(description='Next',button_style='info',tooltip='Loads the PD sync data')\n",
    "\n",
    "\n",
    "        def get_data(b):\n",
    "            input_file = list(uploader_df1.value.values())[0]\n",
    "            content = input_file['content']\n",
    "            #content = io.StringIO(content.decode('utf-8'))\n",
    "\n",
    "            input_file_Name=input_file['metadata']['name']\n",
    "            File_name_temp1=input_file_Name.split('.')\n",
    "            File_type=File_name_temp1[1]\n",
    "            if File_type=='csv':\n",
    "                df1 = pd.read_csv(input_file_Name)\n",
    "            else:\n",
    "                df1 = pd.read_excel(content)    \n",
    "\n",
    "            get_data.data=df1\n",
    "            return get_data.data\n",
    "\n",
    "        # DISPLAY BUTTON\n",
    "        get_data_button.on_click(get_data)\n",
    "\n",
    "        ### B13\n",
    "        get_data_button2 = widgets.Button(description='Next',button_style='info',tooltip='Loads the Rev Projection test data')\n",
    "\n",
    "        Label2A=widgets.Label(f'Please upload the \"Rev Projection test sheet\" in .csv or .xlsx format. For which you want the prediction for')\n",
    "\n",
    "        uploader_df2 = widgets.FileUpload(\n",
    "        #    accept='*.xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "            multiple=True  # True to accept multiple files upload else False\n",
    "        )\n",
    "        #uploader_df2\n",
    "        def get_datadf2(b):\n",
    "            A=[]\n",
    "            df2 = pd.DataFrame()\n",
    "            for i in range(len(uploader_df2.value.values())):\n",
    "                input_file = list(uploader_df2.value.values())[i]\n",
    "                #print(input_file['metadata']['name'])\n",
    "                A.append(input_file['metadata']['name'])\n",
    "                content = input_file['content']\n",
    "\n",
    "                input_file_Name=input_file['metadata']['name']\n",
    "                File_name_temp1=input_file_Name.split('.')\n",
    "                File_type=File_name_temp1[1]\n",
    "                if File_type=='csv':\n",
    "                    df2_temp = pd.read_csv(input_file_Name)\n",
    "                else:\n",
    "                    df2_temp = pd.read_excel(content)    \n",
    "\n",
    "                # This section will extract the month and year information from the file name\n",
    "                File_name=input_file['metadata']['name']\n",
    "                File_name_temp1=File_name.split('.')\n",
    "                File_name_temp2=File_name_temp1[0]\n",
    "                File_name_temp2=File_name_temp2.split('_')\n",
    "                year_info=File_name_temp2[len(File_name_temp2)-1]\n",
    "                month_info=File_name_temp2[len(File_name_temp2)-2]\n",
    "\n",
    "                df2_temp.insert(loc=0, column='Month', value=int(month_info))\n",
    "                df2_temp.insert(loc=0, column='Year', value=int(year_info))\n",
    "\n",
    "                df2=df2.append(df2_temp, ignore_index=True)\n",
    "            get_datadf2.data=df2\n",
    "            return get_datadf2.data   \n",
    "\n",
    "        get_data_button2.on_click(get_datadf2)\n",
    "\n",
    "        Label_Test_1A = widgets.HTML(value=\"<h3> Please upload the 'test data' for prediction </h3>\")\n",
    "\n",
    "        left_box1A=widgets.HBox([uploader_df1,get_data_button])\n",
    "        # left_box1\n",
    "        left_box2A=widgets.HBox([uploader_df2,get_data_button2])\n",
    "        # left_box2\n",
    "        left_boxA=widgets.VBox([Label_Test_1A,Label1A,left_box1A,Label2A,left_box2A])\n",
    "        #left_boxA\n",
    "\n",
    "\n",
    "        ############################################### Model level selection ankd prediction done here ##############################################\n",
    "        ################################################################################################################################\n",
    "        ################################################################################################################################\n",
    "\n",
    "\n",
    "        outputlev = widgets.Output()\n",
    "\n",
    "        level_selector = widgets.RadioButtons(\n",
    "                                 options=['L0','L1','L2'],\n",
    "                                 value=None,\n",
    "                                 description='Select Level: ',\n",
    "                                 disabled=False,\n",
    "        #     layout=widgets.Layout(width='100%')\n",
    "        )\n",
    "\n",
    "        level1_selector = widgets.RadioButtons(\n",
    "                                 options=['GCP','AWS','BFSI', 'TMEG', 'HCLS'],\n",
    "                                 value=None,\n",
    "                                 description='Select Level: ',\n",
    "                                 disabled=False,\n",
    "        #     layout=widgets.Layout(width='100%')\n",
    "        )\n",
    "\n",
    "        level2_selector = widgets.RadioButtons(\n",
    "                                 options=['BFSI-AWS', 'BFSI-Direct', 'BFSI-GCP', 'Region-USCentral','Region-USEast','Region-USWest'],\n",
    "                                 value=None,\n",
    "                                 description='Select Level: ',\n",
    "                                 disabled=False,\n",
    "        )\n",
    "        B = widgets.Button(\n",
    "         description='Format Data',\n",
    "         disabled=False,\n",
    "         button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "         tooltip='Click me',\n",
    "         icon='run'\n",
    "        )\n",
    "        style = {'description_width': 'initial'}\n",
    "        B0 = widgets.Button(\n",
    "         description='Format and predict',\n",
    "         disabled=False,\n",
    "         button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "         tooltip='Click for Format Data and predict',\n",
    "         icon='run',style=style\n",
    "        )\n",
    "\n",
    "        B11 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B12 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B13 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B14 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B15 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "\n",
    "        B21 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B22 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B23 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B24 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B25 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "        B26 = widgets.Button(description='Format and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "\n",
    "        def on_change1(change):\n",
    "            with outputlev:\n",
    "                if change['type'] == 'change' and change['name'] == 'value':\n",
    "                    if change['new'] == 'GCP':\n",
    "                        with outputlev:\n",
    "                            print('GCP Selected')\n",
    "                            display(B11)\n",
    "                    elif change['new'] == 'BFSI':\n",
    "                        with outputlev:\n",
    "                            print('BFSI Selected')\n",
    "                            display(B13)\n",
    "                    elif change['new'] == 'AWS':\n",
    "                        with outputlev:\n",
    "                            print('AWS Selected')  \n",
    "                            display(B12)\n",
    "                    elif change['new'] == 'TMEG':\n",
    "                        with outputlev:\n",
    "                            print('TMEG Selected')\n",
    "                            display(B15)\n",
    "                    elif change['new'] == 'HCLS':\n",
    "                        with outputlev:\n",
    "                            print('HCLS Selected')\n",
    "                            display(B14)\n",
    "\n",
    "        def on_change2(change):\n",
    "            with outputlev:\n",
    "                if change['type'] == 'change' and change['name'] == 'value':\n",
    "                    if change['new'] == 'Region-USCentral':\n",
    "                        with outputlev:\n",
    "                            print('GCP-Region US Central Selected')\n",
    "                            display(B24)\n",
    "                    elif change['new'] =='Region-USEast':\n",
    "                        with outputlev:\n",
    "                            print('GCP-Region US East Selected')\n",
    "                            display(B25)\n",
    "                    elif change['new'] =='Region-USWest':\n",
    "                        with outputlev:\n",
    "                            print('GCP-Region US West Selected')\n",
    "                            display(B26)        \n",
    "                    elif change['new'] =='Practice-CAI':\n",
    "                        with outputlev:\n",
    "                            print('GCP-Practice-Conversational AI Selected')\n",
    "                            display(B27)                     \n",
    "                    elif change['new'] == 'Practice-DA':\n",
    "                        with outputlev:\n",
    "                            print('GCP-Practice-Data Analytics Selected')\n",
    "                            display(B28)\n",
    "                    elif change['new'] == 'BFSI-AWS':\n",
    "                        with outputlev:\n",
    "                            print('BFSI-AWS Selected') \n",
    "                            display(B22)\n",
    "                    elif change['new'] == 'BFSI-Direct':\n",
    "                        with outputlev:\n",
    "                            print('BFSI-Direct Selected')\n",
    "                            display(B23)\n",
    "                    elif change['new'] == 'BFSI-GCP':\n",
    "                        with outputlev:\n",
    "                            print('BFSI-GCP Selected')   \n",
    "                            display(B21)\n",
    "\n",
    "        def selectlevel(button):\n",
    "            with outputlev:\n",
    "                selection = level_selector.get_interact_value()\n",
    "                if (selection == \"L0\"):\n",
    "                    with outputlev:\n",
    "                        print('L0 Level Selected')\n",
    "                        display(B0)                 \n",
    "                elif (selection ==\"L1\"):\n",
    "                        level1_selector.observe(on_change1)\n",
    "                        display(level1_selector)\n",
    "\n",
    "                elif (selection ==\"L2\"):\n",
    "                        level2_selector.observe(on_change2)\n",
    "                        display(level2_selector)\n",
    "\n",
    "        def prediction_L0(button):\n",
    "            with outputlev:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L0,date_ref=L0_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L0\n",
    "                print('Prediction for L0-level')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)\n",
    "\n",
    "                \n",
    "        def prediction_L1_GCP(button):\n",
    "            with outputlev:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L1_GCP\n",
    "                print('Prediction for L1-level: GCP')\n",
    "                print(df)\n",
    "        #         prediction_L1_GCP.data=df\n",
    "        #         return prediction_L1_GCP.data\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)\n",
    "                \n",
    "        def prediction_L1_AWS(button):\n",
    "            with outputlev:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L1_AWS\n",
    "                print('Prediction for L1-level: AWS')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)\n",
    "                \n",
    "        def prediction_L1_BFSI(button):\n",
    "            with outputlev:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L1_BFSI\n",
    "                print('Prediction for L1-level: BFSI')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "                \n",
    "        def prediction_L1_HCLS(button):\n",
    "            with outputlev:\n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L1_HCLS\n",
    "                print('Prediction for L1-level: HCLS')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "                \n",
    "        def prediction_L1_TMEG(button):\n",
    "            with outputlev:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=Predict_L1_TMEG\n",
    "                print('Prediction for L1-level: TMEG')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "\n",
    "        def prediction_L2_BFSI_GCP(button):\n",
    "            with outputlev:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=bfsi_GCP\n",
    "                print('Prediction for L2-level: BFSI-GCP')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "                                \n",
    "        def prediction_L2_BFSI_AWS(button):\n",
    "            with outputlev:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=bfsi_AWS\n",
    "                print('Prediction for L2-level: BFSI-AWS')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "                \n",
    "        def prediction_L2_BFSI_DIR(button):\n",
    "            with outputlev:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=bfsi_DIR\n",
    "                print('Prediction for L2-level: BFSI-Direct')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "                \n",
    "\n",
    "        def prediction_L2_RegionUSCentral(button):\n",
    "            with outputlev:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=USCentral\n",
    "                print('Prediction for L2-level: Region-US Central')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "                \n",
    "        def prediction_L2_RegionUSEast(button):\n",
    "            with outputlev:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=USEast\n",
    "                print('Prediction for L2-level: Region-US East')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "                \n",
    "\n",
    "        def prediction_L2_RegionUSWest(button):\n",
    "            with outputlev:    \n",
    "                df1=get_data.data\n",
    "                df2=get_datadf2.data\n",
    "                bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "                df = pd.DataFrame()\n",
    "                df['Date']=date_ref['ds']\n",
    "                df['Prediction']=USWest\n",
    "                print('Prediction for L2-level: Region-US West')\n",
    "                print(df)\n",
    "                global predict_result\n",
    "                predict_result=df\n",
    "                display(save_prediction)                \n",
    "\n",
    "        lev_button = widgets.Button(\n",
    "        description='Next',\n",
    "        disabled=False,\n",
    "        button_style='info', \n",
    "        tooltip='Run'\n",
    "        )\n",
    "        \n",
    "        def resultSaveFun(button):\n",
    "            predict_result.to_csv(r'Prediction_Result.csv', index = False)\n",
    "\n",
    "\n",
    "        save_prediction = widgets.Button(description='Save Prediction',disabled=False,button_style='info', tooltip='Predicted result will be saved in CSV file')        \n",
    "        save_prediction.on_click(resultSaveFun)       \n",
    "    \n",
    "        # def savingscript(button):\n",
    "        #     if selection=='L1' and levelsub=='GCP':\n",
    "        #         Result_data=prediction_L1_GCP.data\n",
    "        #         Result_data.to_csv(r'prediction_L1_GCP.csv', index = False)\n",
    "        #     elif selection=='L1' and levelsub=='AWS':\n",
    "        #         Result_data=prediction_L1_AWS.data\n",
    "        #         Result_data.to_csv(r'prediction_L1_AWS.csv', index = False)\n",
    "        #     elif selection=='L1' and levelsub=='BFSI':\n",
    "        #         Result_data=prediction_L1_BFSI.data\n",
    "        #         Result_data.to_csv(r'prediction_L1_BFSI.csv', index = False)\n",
    "        #     elif selection=='L1' and levelsub=='HCLS':\n",
    "        #         Result_data=prediction_L1_HCLS.data\n",
    "        #         Result_data.to_csv(r'prediction_L1_HCLS.csv', index = False)\n",
    "        #     elif selection=='L1' and levelsub=='TMEG':\n",
    "        #         Result_data=prediction_L1_TMEG.data\n",
    "        #         Result_data.to_csv(r'prediction_L1_TMEG.csv', index = False)\n",
    "\n",
    "        # #    file_name='prediction'+'_'+selection+'_'+levelsub+'.csv'\n",
    "        # Result_data.to_csv(r'prediction_L1_GCP.csv', index = False)   \n",
    "        # Save_button = widgets.Button(description='Save prediction',disabled=False, button_style='info', tooltip='Save')\n",
    "\n",
    "\n",
    "        lev_button.on_click(selectlevel)\n",
    "        B0.on_click(prediction_L0)\n",
    "        B11.on_click(prediction_L1_GCP)\n",
    "        B12.on_click(prediction_L1_AWS)\n",
    "        B13.on_click(prediction_L1_BFSI)\n",
    "        B14.on_click(prediction_L1_HCLS)\n",
    "        B15.on_click(prediction_L1_TMEG)\n",
    "\n",
    "        B21.on_click(prediction_L2_BFSI_GCP)\n",
    "        B22.on_click(prediction_L2_BFSI_AWS)\n",
    "        B23.on_click(prediction_L2_BFSI_DIR)\n",
    "        B24.on_click(prediction_L2_RegionUSCentral)\n",
    "        B25.on_click(prediction_L2_RegionUSEast)\n",
    "        B26.on_click(prediction_L2_RegionUSWest) \n",
    "\n",
    "        # Save_button.on_click(savingscript)\n",
    "        Label_Train_B11=widgets.HTML(value=\"<h4> There are 3 levels within which the model can generate predictions. These are - L0, L1 and L2. </h4>\")\n",
    "        Label_Train_B12=widgets.HTML(value=\"<h4> L0 - For predictions at Quantiphi level </h4>\")\n",
    "        Label_Train_B13=widgets.HTML(value=\"<h4> L1 - For predictions at Channel vs. BU level </h4>\")\n",
    "        Label_Train_B14=widgets.HTML(value=\"<h4> L2 - For further prediction within a Channel and BU . In channels, only GCP has been considered for prediction due to sufficient data volume. Within GCP predictions can be made for different regions & practices. IN BUs, only BFSI has been considered for predictions due to sufficient data volume. Within BFSI, prediction can be made for deals that are in AWS, GCP and Direct </h4>\")\n",
    "\n",
    "        \n",
    "        left_boxB16 = widgets.VBox([Label_Train_B11,Label_Train_B12,Label_Train_B13,Label_Train_B14])\n",
    "        Label_Test_1B = widgets.HTML(value=\"<h3> Select level of prediction  </h3>\")\n",
    "        left_box1B = widgets.VBox([level_selector, lev_button,outputlev])\n",
    "        left_box2B=widgets.VBox([left_boxA,Label_Test_1B,left_boxB16,left_box1B])#,Save_button])\n",
    "        display(left_box2B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5252b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_selector.get_interact_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409503ce",
   "metadata": {},
   "source": [
    "## Select existing model or re-train model\n",
    "**You can choose to generate predictions with the existing model. Or you can choose to re-train the model with a new dataset.**\n",
    "\n",
    "**Model Selection: 1. Saved model can be loaded, 2. By default previously saved model will be executed **\n",
    "\n",
    "**Test file format: A separate .xlsx or .csv file is required for each month, the file name should be \"FileName_Months_Year\"(Eg: Rev_Projection_01_2022). A single month or multiple months can be selected for prediction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37bcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_selector = widgets.RadioButtons(\n",
    "    options=['Predict with existing model', 'Re-train model'],\n",
    "    value=None,\n",
    "    description='Select: ',\n",
    "    disabled=False\n",
    ")\n",
    "output_box = widgets.Output()\n",
    "# button = widgets.Button(\n",
    "#     description='Next',\n",
    "#     disabled=False,\n",
    "    \n",
    "# )\n",
    "def ev(button):\n",
    "    with output_box:\n",
    "        display('Formatting test data...')\n",
    "        time.sleep(5)\n",
    "        display('Test data formatted')\n",
    "        \n",
    "# button.style.button_color = 'lightblue'\n",
    "my_button1 = widgets.Button(\n",
    "     description='Format Data',\n",
    "     disabled=False,\n",
    "     button_style='info', \n",
    "     tooltip='Run',\n",
    "# #     icon='play'\n",
    ")\n",
    "\n",
    "    \n",
    "def evaluate(button):\n",
    "    with output_box:\n",
    "        selection = dataset_selector.get_interact_value()\n",
    "\n",
    "        if (selection == \"Predict with existing model\"):\n",
    "            print('Predict with existing model selected')\n",
    "            display(lev_button_Test)\n",
    " \n",
    "        elif (selection == \"Re-train model\"):\n",
    "            print('Re-train model selected')\n",
    "            display(lev_button_Train)\n",
    "\n",
    "################################################################################################################################            \n",
    "##########--------------------------------------------------------------------------------------------------------------#######            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "########------------------------------------------------------------------------------------------------------------------######            \n",
    "################################################################################################################################            \n",
    "my_button = widgets.Button(\n",
    "     description='Next',\n",
    "     disabled=False,\n",
    "     button_style='info', \n",
    "     tooltip='Run'\n",
    "# #     icon='play'\n",
    ")\n",
    "style = {'description_width': 'initial'}\n",
    "lev_button_Train = widgets.Button(description='Load training section',disabled=False,button_style='info', tooltip='Training part will be executed. One can train the model freshly and use the trained model for prediction',style=style)\n",
    "lev_button_Test = widgets.Button(description='Load test section',disabled=False,button_style='info', tooltip='Testing part will be executed. One can use pre-existing model to get forecasting',style=style)\n",
    "\n",
    "lev_button_Train.on_click(fun_per_training)\n",
    "lev_button_Test.on_click(fun_handleingTest_section)\n",
    "\n",
    "# output_box = widgets.Output()\n",
    "# # display(my_button, output_box)\n",
    "my_button.on_click(evaluate)\n",
    "left_box = widgets.VBox([dataset_selector, my_button,output_box])\n",
    "widgets.HBox([left_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_selector.get_interact_value()\n",
    "#fun_per_training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# Temp cell For testing ############################33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54643b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting to load the pckl file for FBProphet\n",
    "# uploader_df2 = widgets.FileUpload(\n",
    "#         #accept='*.xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "#         multiple=True  # True to accept multiple files upload else False\n",
    "#     )\n",
    "# uploader_df2\n",
    "#         #uploader_df2\n",
    "#         def get_datadf2(b):\n",
    "#             A=[]\n",
    "#             df2 = pd.DataFrame()\n",
    "#             for i in range(len(uploader_df2.value.values())):\n",
    "#                 input_file = list(uploader_df2.value.values())[i]\n",
    "#                 #print(input_file['metadata']['name'])\n",
    "#                 A.append(input_file['metadata']['name'])\n",
    "#                 content = input_file['content']\n",
    "\n",
    "#                 input_file_Name=input_file['metadata']['name']\n",
    "#                 File_name_temp1=input_file_Name.split('.')\n",
    "#                 File_type=File_name_temp1[1]\n",
    "#                 if File_type=='csv':\n",
    "#                     df2_temp = pd.read_csv(input_file_Name)\n",
    "#                 else:\n",
    "#                     df2_temp = pd.read_excel(content)\n",
    "\n",
    "#                 # This section will extract the month and year information from the file name\n",
    "#                 File_name=input_file['metadata']['name']\n",
    "#                 File_name_temp1=File_name.split('.')\n",
    "#                 File_name_temp2=File_name_temp1[0]\n",
    "#                 File_name_temp2=File_name_temp2.split('_')\n",
    "#                 year_info=File_name_temp2[len(File_name_temp2)-1]\n",
    "#                 month_info=File_name_temp2[len(File_name_temp2)-2]\n",
    "\n",
    "#                 df2_temp.insert(loc=0, column='Month', value=int(month_info))\n",
    "#                 df2_temp.insert(loc=0, column='Year', value=int(year_info))\n",
    "\n",
    "#                 df2=df2.append(df2_temp, ignore_index=True)\n",
    "#             get_datadf2.data=df2      \n",
    "#             return get_datadf2.data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad7ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file = list(uploader_df2.value.values())[0]\n",
    "# #print(input_file['metadata']['name'])\n",
    "# A.append(input_file['metadata']['name'])\n",
    "# content = input_file['content']\n",
    "\n",
    "# input_file_Name=input_file['metadata']['name']\n",
    "# File_name_temp1=input_file_Name.split('.')\n",
    "# File_type=File_name_temp1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36191d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file = list(uploader_df2.value.values())[0]\n",
    "# input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd28be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8952c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploader_df2 = widgets.FileUpload(\n",
    "#         accept='*.pckl',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "#         multiple=True  # True to accept multiple files upload else False\n",
    "#     )\n",
    "# uploader_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cccbc73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e427d914ef2b4114b6dc26db95e4f6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='C:\\Users\\Krishnananda N', filename='', title='', show_hidden=False, select_desc='Select', châ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from ipyfilechooser import FileChooser\n",
    "\n",
    "# # Create and display a FileChooser widget\n",
    "# fc = FileChooser('')\n",
    "# #fc.show_only_dirs = True\n",
    "# display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54644c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Krishnananda N\\\\Downloads\\\\Finalized_Models'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fc.selected_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab5c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc.show_only_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A=fc.selected_path+'\\\\'+arr[0]\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(A, 'rb') as fin:\n",
    "#     model_L1_GCP = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ffe2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_L1_GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B=pd.read_csv(A)\n",
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b71bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(fc.selected_path+arr[0], 'rb') as fin:\n",
    "#     model_L1_GCP = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "108ec196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_FBProphet_L0.pckl',\n",
       " 'model_FBProphet_L1_AWS.pckl',\n",
       " 'model_FBProphet_L1_BFSI.pckl',\n",
       " 'model_FBProphet_L1_GCP.pckl',\n",
       " 'model_FBProphet_L1_HCLS.pckl',\n",
       " 'model_FBProphet_L1_TMEG.pckl',\n",
       " 'model_FBProphet_L2_BFSI_AWS.pckl',\n",
       " 'model_FBProphet_L2_BFSI_DIR.pckl',\n",
       " 'model_FBProphet_L2_BFSI_GCP.pckl',\n",
       " 'model_FBProphet_L2_GCP_Practice_CAI.pckl',\n",
       " 'model_FBProphet_L2_GCP_Practice_DA.pckl',\n",
       " 'model_FBProphet_L2_GCP_Region_USCentral.pckl',\n",
       " 'model_FBProphet_L2_GCP_Region_USEast.pckl',\n",
       " 'model_FBProphet_L2_GCP_Region_USWest.pckl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arr = os.listdir(fc.selected_path)\n",
    "# arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163f231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loadingL1_Model_pcklfile():\n",
    "#     with open('model_FBProphet_L1_GCP.pckl', 'rb') as fin:\n",
    "#         model_L1_GCP = pickle.load(fin)\n",
    "#     with open('model_FBProphet_L1_AWS.pckl', 'rb') as fin:\n",
    "#         model_L1_AWS = pickle.load(fin)\n",
    "#     with open('model_FBProphet_L1_BFSI.pckl', 'rb') as fin:\n",
    "#         model_L1_BFSI = pickle.load(fin)\n",
    "#     with open('model_FBProphet_L1_HCLS.pckl', 'rb') as fin:\n",
    "#         model_L1_HCLS = pickle.load(fin)\n",
    "#     with open('model_FBProphet_L1_TMEG.pckl', 'rb') as fin:\n",
    "#         model_L1_TMEG = pickle.load(fin)\n",
    "#     return model_L1_GCP,model_L1_AWS,model_L1_BFSI,model_L1_HCLS,model_L1_TMEG\n",
    "    \n",
    "# # loading L2-Level model #\n",
    "# def loadingL2_Model_pcklfile():\n",
    "#     with open('model_FBProphet_L2_BFSI_GCP.pckl', 'rb') as fin:\n",
    "#         model_L2_BFSI_GCP = pickle.load(fin)\n",
    "#     with open('model_FBProphet_L2_BFSI_AWS.pckl', 'rb') as fin:\n",
    "#         model_L2_BFSI_AWS = pickle.load(fin)\n",
    "#     with open('model_FBProphet_L2_BFSI_DIR.pckl', 'rb') as fin:\n",
    "#         model_L2_BFSI_DIR = pickle.load(fin)\n",
    "#     with open('model_FBProphet_L2_GCP_Region_USEast.pckl', 'rb') as fin:\n",
    "#         model_L2_Region_USEast = pickle.load(fin)\n",
    "#     with open('model_FBProphet_L2_GCP_Region_USWest.pckl', 'rb') as fin:\n",
    "#         model_L2_Region_USWest = pickle.load(fin)\n",
    "#     with open('model_FBProphet_L2_GCP_Region_USCentral.pckl', 'rb') as fin:\n",
    "#         model_L2_Region_USCentral = pickle.load(fin)\n",
    "#     with open('model_FBProphet_L2_GCP_Practice_DA.pckl', 'rb') as fin:\n",
    "#         model_L2_Practice_DA = pickle.load(fin)\n",
    "#     with open('model_FBProphet_L2_GCP_Practice_CAI.pckl', 'rb') as fin:\n",
    "#         model_L2_Practice_CAI = pickle.load(fin)\n",
    "#     return model_L2_BFSI_GCP,model_L2_BFSI_AWS,model_L2_BFSI_DIR,model_L2_Region_USCentral,model_L2_Region_USEast,model_L2_Region_USWest,model_L2_Practice_CAI,model_L2_Practice_DA    \n",
    "# # Loading L0-Level model\n",
    "# def loadingL0_Model_pcklfile():\n",
    "#     with open('model_FBProphet_L0.pckl', 'rb') as fin:\n",
    "#         model_L0 = pickle.load(fin)\n",
    "#     return model_L0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c7a06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec0d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e0df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ac215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e95aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8864524b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4f307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                         ###  Is an important consolidated code dont delet it ###\n",
    "\n",
    "\n",
    "# ################Training section note book is written here\n",
    "# ############################################### This Flow is for Training Section ##############################################\n",
    "# ########################################### Training and Test data will be loaded here #########################################\n",
    "# ################################################################################################################################\n",
    "\n",
    "# Label1=widgets.Label(\"Please upload the recent 'PD SYNC' file in .csv or .xlsx format\")\n",
    "# uploader_df1 = widgets.FileUpload(#accept='*.xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "#     multiple=False)  # True to accept multiple files upload else False)\n",
    "\n",
    "# #display(uploader_df1.value) \n",
    "\n",
    "# get_data_button = widgets.Button(description='Next',button_style='info',tooltip='Loads the PD sync data')\n",
    "\n",
    "\n",
    "# def get_data(b):\n",
    "#     input_file = list(uploader_df1.value.values())[0]\n",
    "#     content = input_file['content']\n",
    "#     #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "#     input_file_Name=input_file['metadata']['name']\n",
    "#     File_name_temp1=input_file_Name.split('.')\n",
    "#     File_type=File_name_temp1[1]\n",
    "#     if File_type=='csv':\n",
    "#         df1 = pd.read_csv(input_file_Name)\n",
    "#     else:\n",
    "#         df1 = pd.read_excel(content)\n",
    "        \n",
    "#     get_data.data=df1\n",
    "#     return get_data.data\n",
    "\n",
    "# ###### B22\n",
    "# #print('Please upload PDSync test data in .csv / .xlsx format to generate predictions')\n",
    "\n",
    "# Label2Train=widgets.Label(\"Please upload the 'Rev Projection Training sheet' file in .csv or .xlsx format\")\n",
    "# uploader_df2Train = widgets.FileUpload(#accept='*.xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "#     multiple=False)  # True to accept multiple files upload else False)\n",
    "\n",
    "# #display(uploader_df2Train.value) \n",
    "\n",
    "# get_data_button2Train = widgets.Button(description='Next',button_style='info',tooltip='Loads the Rev Projection data for Training')\n",
    "\n",
    "# def get_datadf2Train(b):\n",
    "#     input_file = list(uploader_df2Train.value.values())[0]\n",
    "#     content = input_file['content']\n",
    "#     #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "#     input_file_Name=input_file['metadata']['name']\n",
    "#     File_name_temp1=input_file_Name.split('.')\n",
    "#     File_type=File_name_temp1[1]\n",
    "#     if File_type=='csv':\n",
    "#         df2 = pd.read_csv(input_file_Name)\n",
    "#     else:\n",
    "#         df2 = pd.read_excel(content)\n",
    "#     get_datadf2Train.data=df2\n",
    "    \n",
    "#     return get_datadf2Train.data\n",
    "\n",
    "\n",
    "# ###### B13\n",
    "# get_data_button2 = widgets.Button(description='Next',button_style='info',tooltip='Loads the Rev Projection test data')\n",
    "\n",
    "# Label2=widgets.Label(f'Please upload the \"Rev Projection Test sheet\" in .csv or .xlsx format. For which you want the prediction for')\n",
    "\n",
    "# uploader_df2 = widgets.FileUpload(\n",
    "#     #accept='*.xlsx',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "#     multiple=True  # True to accept multiple files upload else False\n",
    "# )\n",
    "# #uploader_df2\n",
    "# def get_datadf2(b):\n",
    "#     A=[]\n",
    "#     df2 = pd.DataFrame()\n",
    "#     for i in range(len(uploader_df2.value.values())):\n",
    "#         input_file = list(uploader_df2.value.values())[i]\n",
    "#         #print(input_file['metadata']['name'])\n",
    "#         A.append(input_file['metadata']['name'])\n",
    "#         content = input_file['content']\n",
    "\n",
    "#         input_file_Name=input_file['metadata']['name']\n",
    "#         File_name_temp1=input_file_Name.split('.')\n",
    "#         File_type=File_name_temp1[1]\n",
    "#         if File_type=='csv':\n",
    "#             df2_temp = pd.read_csv(input_file_Name)\n",
    "#         else:\n",
    "#             df2_temp = pd.read_excel(content)\n",
    "\n",
    "#         # This section will extract the month and year information from the file name\n",
    "#         File_name=input_file['metadata']['name']\n",
    "#         File_name_temp1=File_name.split('.')\n",
    "#         File_name_temp2=File_name_temp1[0]\n",
    "#         File_name_temp2=File_name_temp2.split('_')\n",
    "#         year_info=File_name_temp2[len(File_name_temp2)-1]\n",
    "#         month_info=File_name_temp2[len(File_name_temp2)-2]\n",
    "\n",
    "#         df2_temp.insert(loc=0, column='Month', value=int(month_info))\n",
    "#         df2_temp.insert(loc=0, column='Year', value=int(year_info))\n",
    "\n",
    "#         df2=df2.append(df2_temp, ignore_index=True)\n",
    "#     get_datadf2.data=df2      \n",
    "#     return get_datadf2.data   \n",
    "\n",
    "# # DISPLAY BUTTON\n",
    "# get_data_button.on_click(get_data)   \n",
    "# get_data_button2Train.on_click(get_datadf2Train)\n",
    "# get_data_button2.on_click(get_datadf2)\n",
    "\n",
    "# Label_Train_1 = widgets.HTML(value=\"<h3> Please upload the dataset for Training and data for future prediction </h3>\")\n",
    "\n",
    "# left_box1A=widgets.HBox([uploader_df1,get_data_button])\n",
    "# left_box2Train=widgets.HBox([uploader_df2Train,get_data_button2Train])\n",
    "# # left_box1\n",
    "# left_box2A=widgets.HBox([uploader_df2,get_data_button2])\n",
    "# # left_box2\n",
    "# left_boxA=widgets.VBox([Label_Train_1,Label1,left_box1A,Label2Train,left_box2Train,Label2,left_box2A])\n",
    "# #\n",
    "\n",
    "\n",
    "# ############################################## Model Level information is taken  ###############################################\n",
    "# ################################################## model will be trained here ##################################################\n",
    "# ################################################################################################################################\n",
    "\n",
    "# outputlev = widgets.Output()\n",
    "# style = {'description_width': 'initial'}\n",
    "# level_selector = widgets.RadioButtons(\n",
    "#                          options=['L0','L1','L2'],\n",
    "#                          value=None,\n",
    "#                          description='Choose model Level : ',\n",
    "#                          disabled=False,style=style,\n",
    "# #     layout=widgets.Layout(width='100%')\n",
    "# )\n",
    "\n",
    "# Bt0 = widgets.Button(description='Start Training',disabled=False,button_style='info',tooltip='Model will be trained for L0 level', icon='run')\n",
    "# Bt1 = widgets.Button(description='Start Training',disabled=False,button_style='info', tooltip='Model will be trained for L1 level (GCP, AWS, BFSI, HCLS, TMEG)',icon='run')\n",
    "# Bt2 = widgets.Button(description='Start Training',disabled=False,button_style='info', tooltip='Model will be trained for L2 levle (BFSI-GCP, BFSI-AWS, BFSI-Direct, Region-USCentral, Region-USEast, Region-USWest, Practice-GCP-Data Analytics)',icon='run')\n",
    "                                                                                                                                                                 \n",
    "# def selectlevel(button):\n",
    "#     with outputlev:\n",
    "#         selection = level_selector.get_interact_value()\n",
    "#         if (selection == \"L0\"):\n",
    "#             with outputlev:\n",
    "#                 print('Selected the L0-Level for training model')\n",
    "#                 display(Validation_months)\n",
    "#                 display(Bt0)                 \n",
    "#         elif (selection ==\"L1\"):\n",
    "#                 print('Selected the L1-Level for training model')\n",
    "# #                level1_selector.observe(on_change1)\n",
    "#                 display(Validation_months)\n",
    "#                 display(Bt1)\n",
    "\n",
    "#         elif (selection ==\"L2\"):\n",
    "#                 print('Selected the L2-Level for training model')\n",
    "# #                level2_selector.observe(on_change2)\n",
    "#                 display(Validation_months)\n",
    "#                 display(Bt2)\n",
    "\n",
    "# def train_model_L0(button):\n",
    "#     with outputlev:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2Train.data\n",
    "# #         print('L0 section')\n",
    "# #         print('df1 size=',df1.shape)\n",
    "# #         print('df2 size=',df2.shape)\n",
    "#         # model training section\n",
    "#         df_L0=dataPrepartaionL0_FbProphet(df1,df2)\n",
    "#         number_validation_month=Validation_months.value\n",
    "#         Model_L0,MAPE_L0=training_L0_L1_model_FBProphet(df_L0,num_Val=number_validation_month)\n",
    "#         save_training_model_L0(Model_L0)\n",
    "#         print('Validation result for L0-level')\n",
    "#         print(MAPE_L0)\n",
    "# #         Predict_L0,date_ref=L0_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "# #         df = pd.DataFrame()\n",
    "# #         df['Date']=date_ref['ds']\n",
    "# #         df['Prediction']=Predict_L0\n",
    "# #         print('Prediction for L0-level')\n",
    "# #         print(df)\n",
    "                  \n",
    "# def train_model_L1(button):\n",
    "#     with outputlev:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2Train.data\n",
    "#         temp1,temp2,temp3,temp4,temp5,RF_V2_GCP,RF_V2_AWS,RF_V2_BFSI,RF_V2_HCLS,RF_V2_TMEG=dataPrepartaionL1(df1,df2)\n",
    "#         number_validation_month=Validation_months.value\n",
    "#         Model_L1_GCP,MAPE_L1_GCP=training_L0_L1_model_FBProphet(RF_V2_GCP,num_Val=number_validation_month)\n",
    "#         Model_L1_AWS,MAPE_L1_AWS=training_L0_L1_model_FBProphet(RF_V2_AWS,num_Val=number_validation_month)\n",
    "#         Model_L1_BFSI,MAPE_L1_BFSI=training_L0_L1_model_FBProphet(RF_V2_BFSI,num_Val=number_validation_month)\n",
    "#         Model_L1_HCLS,MAPE_L1_HCLS=training_L0_L1_model_FBProphet(RF_V2_HCLS,num_Val=number_validation_month)\n",
    "#         Model_L1_TMEG,MAPE_L1_TMEG=training_L0_L1_model_FBProphet(RF_V2_TMEG,num_Val=number_validation_month)\n",
    "#         save_training_model_L1(Model_L1_GCP,Model_L1_AWS,Model_L1_BFSI,Model_L1_HCLS,Model_L1_TMEG)\n",
    "#         print('Validation result for L1-level')\n",
    "#         print('GCP')\n",
    "#         print(MAPE_L1_GCP)\n",
    "#         print('AWS')\n",
    "#         print(MAPE_L1_AWS)\n",
    "#         print('BFSI')\n",
    "#         print(MAPE_L1_BFSI)\n",
    "#         print('HCLS')\n",
    "#         print(MAPE_L1_HCLS)\n",
    "#         print('TMEG')\n",
    "#         print(MAPE_L1_TMEG)        \n",
    "        \n",
    "# #         print('df1 size=',df1.shape)\n",
    "# #         print('df2 size=',df2.shape) \n",
    "        \n",
    "        \n",
    "# #         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "# #         df = pd.DataFrame()\n",
    "# #         df['Date']=date_ref['ds']\n",
    "# #         df['Prediction']=Predict_L1_GCP\n",
    "# #         print('Prediction for L1-level: GCP')\n",
    "# #         print(df)        \n",
    "    \n",
    "# def train_model_L2(button):\n",
    "#     with outputlev:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2Train.data\n",
    "#         number_validation_month=Validation_months.value\n",
    "#         df_gcp_USEast,df_gcp_USWest,df_gcp_USCentral,df_gcp_Practice_DA,df_gcp_Practice_CAI,df_bfsi_gcp,df_bfsi_aws,df_bfsi_dir=dataPrepartaionL2_FBProphet(df1,df2)\n",
    "#         Model_L2_Region_USEast,MAPE_L2_Region_USEast=training_L2_model_FBProphet(df_gcp_USEast,num_Val=number_validation_month,Database='Region_USEast')\n",
    "#         Model_L2_Region_USWest,MAPE_L2_Region_USWest=training_L2_model_FBProphet(df_gcp_USWest,num_Val=number_validation_month,Database='Region_USWest')\n",
    "#         Model_L2_Region_USCentral,MAPE_L2_Region_USCentral=training_L2_model_FBProphet(df_gcp_USCentral,num_Val=number_validation_month,Database='Region_USCentral')\n",
    "\n",
    "#         Model_L2_Practice_DA,MAPE_L2_Practice_DA=training_L2_model_FBProphet(df_gcp_Practice_DA,num_Val=number_validation_month,Database='Practice_DA')\n",
    "#         Model_L2_Practice_CAI,MAPE_L2_Practice_CAI=training_L2_model_FBProphet(df_gcp_Practice_CAI,num_Val=number_validation_month,Database='Practice_CAI')\n",
    "\n",
    "#         Model_L2_BFSI_GCP,MAPE_L2_BFSI_GCP=training_L2_model_FBProphet(df_bfsi_gcp,num_Val=number_validation_month,Database='BFSI_GCP')\n",
    "#         Model_L2_BFSI_AWS,MAPE_L2_BFSI_AWS=training_L2_model_FBProphet(df_bfsi_aws,num_Val=number_validation_month,Database='BFSI_AWS')\n",
    "#         Model_L2_BFSI_DIR,MAPE_L2_BFSI_DIR=training_L2_model_FBProphet(df_bfsi_dir,num_Val=number_validation_month,Database='BFSI_DIR')\n",
    "\n",
    "#         save_training_model_L2(Model_L2_BFSI_GCP,Model_L2_BFSI_AWS,Model_L2_BFSI_DIR,Model_L2_Region_USEast,Model_L2_Region_USWest,Model_L2_Region_USCentral,Model_L2_Practice_DA,Model_L2_Practice_CAI)        \n",
    "#         print('Validation result for L2-level')\n",
    "#         print('BFSI-GCP')\n",
    "#         print(MAPE_L2_BFSI_GCP)\n",
    "#         print('BFSI-AWS')\n",
    "#         print(MAPE_L2_BFSI_AWS)\n",
    "#         print('BFSI-Direct')\n",
    "#         print(MAPE_L2_BFSI_DIR)\n",
    "#         print('GCP-Region-USEast')\n",
    "#         print(MAPE_L2_Region_USEast)\n",
    "#         print('GCP-Region-USWest')\n",
    "#         print(MAPE_L2_Region_USWest) \n",
    "#         print('GCP-Region-USCentral')\n",
    "#         print(MAPE_L2_Region_USCentral)         \n",
    "#         print('GCP-Practice-Conversational AI')\n",
    "#         print(MAPE_L2_Practice_CAI) \n",
    "#         print('GCP-Practice- Data Analytics')\n",
    "#         print(MAPE_L2_Practice_DA)\n",
    "        \n",
    "# #         print('L2 section')\n",
    "# #         print('df1 size=',df1.shape)\n",
    "# #         print('df2 size=',df2.shape)        \n",
    "# #         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "# #         df = pd.DataFrame()\n",
    "# #         df['Date']=date_ref['ds']\n",
    "# #         df['Prediction']=bfsi_GCP\n",
    "# #         print('Prediction for L2-level: BFSI-GCP')\n",
    "# #         print(df)\n",
    "    \n",
    "# lev_button = widgets.Button(\n",
    "# description='Next',\n",
    "# disabled=False,\n",
    "# button_style='info', \n",
    "# tooltip='Confirm the model level selection'\n",
    "# )\n",
    "\n",
    "# lev_button.on_click(selectlevel)\n",
    "# Bt0.on_click(train_model_L0)\n",
    "# Bt1.on_click(train_model_L1)\n",
    "# Bt2.on_click(train_model_L2)\n",
    "\n",
    "# style = {'description_width': 'initial'}\n",
    "# Validation_months=widgets.BoundedIntText(\n",
    "#     value=2,\n",
    "#     min=0,\n",
    "#     max=10,\n",
    "#     step=1,\n",
    "#     description='Choose num of Validation months:',\n",
    "#     disabled=False, style=style\n",
    "# )\n",
    "\n",
    "# Label_Train_21=widgets.HTML(value=\"<h2> Select level of training/ tesing</h2>\")\n",
    "# Label_Train_22=widgets.HTML(value=\"<h3> What are Levels? </h3>\")\n",
    "# Label_Train_23=widgets.HTML(value=\"<h3> There are 3 levels within which the model can generate predictions. These are - L0, L1 and L2. </h3>\")\n",
    "# Label_Train_24=widgets.HTML(value=\"<h3> L0 - For predictions at Quantiphi level </h3>\")\n",
    "# Label_Train_25=widgets.HTML(value=\"<h3> L1 - For predictions at Channel vs. BU level </h3>\")\n",
    "# Label_Train_26=widgets.HTML(value=\"<h3> L2 - For further prediction within a Channel and BU . In channels, only GCP has been considered for prediction due to sufficient data volume. Within GCP predictions can be made for different regions & practices. </h3>\")\n",
    "# Label_Train_27=widgets.HTML(value=\"<h3> IN BUs, only BFSI has been considered for predictions due to sufficient data volume. Within BFSI, prediction can be made for deals that are in AWS, GCP and Direct </h3>\")\n",
    "# Label_Train_28=widgets.HTML(value=\"<h4> Note: For demo purpose the hyperparameter length is reduced </h4>\")\n",
    "  \n",
    "# label_boxB=widgets.VBox([Label_Train_21,Label_Train_22,Label_Train_23,Label_Train_24,Label_Train_25,Label_Train_26,Label_Train_27,Label_Train_28])\n",
    "# left_box1B = widgets.HBox([level_selector, lev_button])\n",
    "# #left_box2 = widgets.HBox([Validation_months, outputlev])\n",
    "# left_box3B = widgets.VBox([left_boxA,label_boxB,left_box1B,outputlev])\n",
    "# #left_box3\n",
    "\n",
    "# # left_box1=widgets.HBox([uploader_df1,get_data_button])\n",
    "# # left_box2Train=widgets.HBox([uploader_df2Train,get_data_button2Train])\n",
    "# # # left_box1\n",
    "# # left_box2=widgets.HBox([uploader_df2,get_data_button2])\n",
    "# # # left_box2\n",
    "# # left_box=widgets.VBox([Label1,left_box1,Label2Train,left_box2Train,Label2,left_box2])\n",
    "# # left_box\n",
    "\n",
    "\n",
    "# ####################################### Newly trained Model will be tested here  ##############################################\n",
    "# ########################################### Prediction result will be given ###################################################\n",
    "# ###############################################################################################################################\n",
    "\n",
    "# outputlev1 = widgets.Output()\n",
    "\n",
    "# level1_selector = widgets.RadioButtons(\n",
    "#                          options=['GCP','AWS','BFSI', 'TMEG', 'HCLS'],\n",
    "#                          value=None,\n",
    "#                          description='Select Level: ',\n",
    "#                          disabled=False,\n",
    "# #     layout=widgets.Layout(width='100%')\n",
    "# )\n",
    "\n",
    "# level2_selector = widgets.RadioButtons(\n",
    "#                          options=['BFSI-AWS', 'BFSI-Direct', 'BFSI-GCP', 'Region-USCentral','Region-USEast','Region-USWest'],\n",
    "#                          value=None,\n",
    "#                          description='Select Level: ',\n",
    "#                          disabled=False,\n",
    "# )\n",
    "# B = widgets.Button(\n",
    "#  description='Format Data',\n",
    "#  disabled=False,\n",
    "#  button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "#  tooltip='Click me',\n",
    "#  icon='run'\n",
    "# )\n",
    "# style = {'description_width': 'initial'}\n",
    "# B0 = widgets.Button(\n",
    "#  description='Format Data and predict',\n",
    "#  disabled=False,\n",
    "#  button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "#  tooltip='Click for Format Data and predict',\n",
    "#  icon='run',style=style\n",
    "# )\n",
    "\n",
    "# B11 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B12 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B13 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B14 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B15 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "\n",
    "# B21 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B22 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B23 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B24 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B25 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B26 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "\n",
    "# def on_change1(change):\n",
    "#     with outputlev:\n",
    "#         if change['type'] == 'change' and change['name'] == 'value':\n",
    "#             if change['new'] == 'GCP':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP Selected')\n",
    "#                     display(B11)\n",
    "#             elif change['new'] == 'BFSI':\n",
    "#                 with outputlev1:\n",
    "#                     print('BFSI Selected')\n",
    "#                     display(B13)\n",
    "#             elif change['new'] == 'AWS':\n",
    "#                 with outputlev1:\n",
    "#                     print('AWS Selected')  \n",
    "#                     display(B12)\n",
    "#             elif change['new'] == 'TMEG':\n",
    "#                 with outputlev1:\n",
    "#                     print('TMEG Selected')\n",
    "#                     display(B15)\n",
    "#             elif change['new'] == 'HCLS':\n",
    "#                 with outputlev1:\n",
    "#                     print('HCLS Selected')\n",
    "#                     display(B14)\n",
    "                    \n",
    "# def on_change2(change):\n",
    "#     with outputlev1:\n",
    "#         if change['type'] == 'change' and change['name'] == 'value':\n",
    "#             if change['new'] == 'Region-USCentral':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP-Region US Central Selected')\n",
    "#                     display(B24)\n",
    "#             elif change['new'] =='Region-USEast':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP-Region US East Selected')\n",
    "#                     display(B25)\n",
    "#             elif change['new'] =='Region-USWest':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP-Region US West Selected')\n",
    "#                     display(B26)        \n",
    "#             elif change['new'] =='Practice-CAI':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP-Practice-Conversational AI Selected')\n",
    "#                     display(B27)                     \n",
    "#             elif change['new'] == 'Practice-DA':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP-Practice-Data Analytics Selected')\n",
    "#                     display(B28)\n",
    "#             elif change['new'] == 'BFSI-AWS':\n",
    "#                 with outputlev1:\n",
    "#                     print('BFSI-AWS Selected') \n",
    "#                     display(B22)\n",
    "#             elif change['new'] == 'BFSI-Direct':\n",
    "#                 with outputlev1:\n",
    "#                     print('BFSI-Direct Selected')\n",
    "#                     display(B23)\n",
    "#             elif change['new'] == 'BFSI-GCP':\n",
    "#                 with outputlev1:\n",
    "#                     print('BFSI-GCP Selected')   \n",
    "#                     display(B21)\n",
    "\n",
    "# def selectlevel(button):\n",
    "#     with outputlev1:\n",
    "#         selection = level_selector.get_interact_value()\n",
    "#         if (selection == \"L0\"):\n",
    "#             with outputlev1:\n",
    "#                 print('L0 Level Selected')\n",
    "#                 display(B0)                 \n",
    "#         elif (selection ==\"L1\"):\n",
    "#                 level1_selector.observe(on_change1)\n",
    "#                 display(level1_selector)\n",
    "\n",
    "#         elif (selection ==\"L2\"):\n",
    "#                 level2_selector.observe(on_change2)\n",
    "#                 display(level2_selector)\n",
    "\n",
    "# def prediction_L0(button):\n",
    "#     with outputlev1:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L0,date_ref=L0_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L0\n",
    "#         print('Prediction for L0-level')\n",
    "#         print(df)\n",
    "                  \n",
    "# def prediction_L1_GCP(button):\n",
    "#     with outputlev1:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L1_GCP\n",
    "#         print('Prediction for L1-level: GCP')\n",
    "#         print(df)        \n",
    "\n",
    "# def prediction_L1_AWS(button):\n",
    "#     with outputlev1:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L1_AWS\n",
    "#         print('Prediction for L1-level: AWS')\n",
    "#         print(df)\n",
    "        \n",
    "# def prediction_L1_BFSI(button):\n",
    "#     with outputlev1:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L1_BFSI\n",
    "#         print('Prediction for L1-level: BFSI')\n",
    "#         print(df)\n",
    "\n",
    "# def prediction_L1_HCLS(button):\n",
    "#     with outputlev1:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L1_HCLS\n",
    "#         print('Prediction for L1-level: HCLS')\n",
    "#         print(df)\n",
    "\n",
    "# def prediction_L1_TMEG(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L1_TMEG\n",
    "#         print('Prediction for L1-level: TMEG')\n",
    "#         print(df)\n",
    "\n",
    "       \n",
    "     \n",
    "# def prediction_L2_BFSI_GCP(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=bfsi_GCP\n",
    "#         print('Prediction for L2-level: BFSI-GCP')\n",
    "#         print(df)\n",
    "\n",
    "# def prediction_L2_BFSI_AWS(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=bfsi_AWS\n",
    "#         print('Prediction for L2-level: BFSI-AWS')\n",
    "#         print(df)\n",
    " \n",
    "     \n",
    "# def prediction_L2_BFSI_DIR(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=bfsi_DIR\n",
    "#         print('Prediction for L2-level: BFSI-Direct')\n",
    "#         print(df)\n",
    "\n",
    "\n",
    "# def prediction_L2_RegionUSCentral(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=USCentral\n",
    "#         print('Prediction for L2-level: Region-US Central')\n",
    "#         print(df)\n",
    "\n",
    "\n",
    "# def prediction_L2_RegionUSEast(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=USEast\n",
    "#         print('Prediction for L2-level: Region-US East')\n",
    "#         print(df)\n",
    "\n",
    "\n",
    "# def prediction_L2_RegionUSWest(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=USWest\n",
    "#         print('Prediction for L2-level: Region-US West')\n",
    "#         print(df)\n",
    "            \n",
    "    \n",
    "# lev_button1 = widgets.Button(\n",
    "# description='Next',\n",
    "# disabled=False,\n",
    "# button_style='info', \n",
    "# tooltip='click to get prediction for test data'\n",
    "# )\n",
    "\n",
    "# lev_button1.on_click(selectlevel)\n",
    "# B0.on_click(prediction_L0)\n",
    "# B11.on_click(prediction_L1_GCP)\n",
    "# B12.on_click(prediction_L1_AWS)\n",
    "# B13.on_click(prediction_L1_BFSI)\n",
    "# B14.on_click(prediction_L1_HCLS)\n",
    "# B15.on_click(prediction_L1_TMEG)\n",
    "\n",
    "# B21.on_click(prediction_L2_BFSI_GCP)\n",
    "# B22.on_click(prediction_L2_BFSI_AWS)\n",
    "# B23.on_click(prediction_L2_BFSI_DIR)\n",
    "# B24.on_click(prediction_L2_RegionUSCentral)\n",
    "# B25.on_click(prediction_L2_RegionUSEast)\n",
    "# B26.on_click(prediction_L2_RegionUSWest) \n",
    "\n",
    "# Label_3C = widgets.HTML(value=\"<h2> Prediction using newly trained model</h2>\")\n",
    "# #Label2Train=widgets.Label(\"Please upload the 'Rev Projection Training sheet' file in .csv or .xlsx format\")\n",
    "# left_box5C = widgets.VBox([lev_button1,outputlev1])\n",
    "# widgets.VBox([left_box3B,Label_3C,left_box5C])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6eb8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f666211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputlev = widgets.Output()\n",
    "# style = {'description_width': 'initial'}\n",
    "# level_selector = widgets.RadioButtons(\n",
    "#                          options=['L0','L1','L2'],\n",
    "#                          value=None,\n",
    "#                          description='Choose model Level : ',\n",
    "#                          disabled=False,style=style,\n",
    "# #     layout=widgets.Layout(width='100%')\n",
    "# )\n",
    "\n",
    "# Bt0 = widgets.Button(description='Start Training',disabled=False,button_style='info',tooltip='Model will be trained for L0 level', icon='run')\n",
    "# Bt1 = widgets.Button(description='Start Training',disabled=False,button_style='info', tooltip='Model will be trained for L1 level (GCP, AWS, BFSI, HCLS, TMEG)',icon='run')\n",
    "# Bt2 = widgets.Button(description='Start Training',disabled=False,button_style='info', tooltip='Model will be trained for L2 levle (BFSI-GCP, BFSI-AWS, BFSI-Direct, Region-USCentral, Region-USEast, Region-USWest, Practice-GCP-Data Analytics)',icon='run')\n",
    "                                                                                                                                                                 \n",
    "# def selectlevel(button):\n",
    "#     with outputlev:\n",
    "#         selection = level_selector.get_interact_value()\n",
    "#         if (selection == \"L0\"):\n",
    "#             with outputlev:\n",
    "#                 print('Selected the L0-Level for training model')\n",
    "#                 display(Validation_months)\n",
    "#                 display(Bt0)                 \n",
    "#         elif (selection ==\"L1\"):\n",
    "#                 print('Selected the L1-Level for training model')\n",
    "# #                level1_selector.observe(on_change1)\n",
    "#                 display(Validation_months)\n",
    "#                 display(Bt1)\n",
    "\n",
    "#         elif (selection ==\"L2\"):\n",
    "#                 print('Selected the L2-Level for training model')\n",
    "# #                level2_selector.observe(on_change2)\n",
    "#                 display(Validation_months)\n",
    "#                 display(Bt2)\n",
    "\n",
    "# def train_model_L0(button):\n",
    "#     with outputlev:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2Train.data\n",
    "# #         print('L0 section')\n",
    "# #         print('df1 size=',df1.shape)\n",
    "# #         print('df2 size=',df2.shape)\n",
    "#         # model training section\n",
    "#         df_L0=dataPrepartaionL0_FbProphet(df1,df2)\n",
    "#         number_validation_month=Validation_months.value\n",
    "#         Model_L0,MAPE_L0=training_L0_L1_model_FBProphet(df_L0,num_Val=number_validation_month)\n",
    "#         save_training_model_L0(Model_L0)\n",
    "#         print('Validation result for L0-level')\n",
    "#         print(MAPE_L0)\n",
    "# #         Predict_L0,date_ref=L0_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "# #         df = pd.DataFrame()\n",
    "# #         df['Date']=date_ref['ds']\n",
    "# #         df['Prediction']=Predict_L0\n",
    "# #         print('Prediction for L0-level')\n",
    "# #         print(df)\n",
    "                  \n",
    "# def train_model_L1(button):\n",
    "#     with outputlev:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2Train.data\n",
    "#         temp1,temp2,temp3,temp4,temp5,RF_V2_GCP,RF_V2_AWS,RF_V2_BFSI,RF_V2_HCLS,RF_V2_TMEG=dataPrepartaionL1(df1,df2)\n",
    "#         number_validation_month=Validation_months.value\n",
    "#         Model_L1_GCP,MAPE_L1_GCP=training_L0_L1_model_FBProphet(RF_V2_GCP,num_Val=number_validation_month)\n",
    "#         Model_L1_AWS,MAPE_L1_AWS=training_L0_L1_model_FBProphet(RF_V2_AWS,num_Val=number_validation_month)\n",
    "#         Model_L1_BFSI,MAPE_L1_BFSI=training_L0_L1_model_FBProphet(RF_V2_BFSI,num_Val=number_validation_month)\n",
    "#         Model_L1_HCLS,MAPE_L1_HCLS=training_L0_L1_model_FBProphet(RF_V2_HCLS,num_Val=number_validation_month)\n",
    "#         Model_L1_TMEG,MAPE_L1_TMEG=training_L0_L1_model_FBProphet(RF_V2_TMEG,num_Val=number_validation_month)\n",
    "#         save_training_model_L1(Model_L1_GCP,Model_L1_AWS,Model_L1_BFSI,Model_L1_HCLS,Model_L1_TMEG)\n",
    "#         print('Validation result for L1-level')\n",
    "#         print('GCP')\n",
    "#         print(MAPE_L1_GCP)\n",
    "#         print('AWS')\n",
    "#         print(MAPE_L1_AWS)\n",
    "#         print('BFSI')\n",
    "#         print(MAPE_L1_BFSI)\n",
    "#         print('HCLS')\n",
    "#         print(MAPE_L1_HCLS)\n",
    "#         print('TMEG')\n",
    "#         print(MAPE_L1_TMEG)        \n",
    "        \n",
    "# #         print('df1 size=',df1.shape)\n",
    "# #         print('df2 size=',df2.shape) \n",
    "        \n",
    "        \n",
    "# #         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "# #         df = pd.DataFrame()\n",
    "# #         df['Date']=date_ref['ds']\n",
    "# #         df['Prediction']=Predict_L1_GCP\n",
    "# #         print('Prediction for L1-level: GCP')\n",
    "# #         print(df)        \n",
    "    \n",
    "# def train_model_L2(button):\n",
    "#     with outputlev:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2Train.data\n",
    "#         number_validation_month=Validation_months.value\n",
    "#         df_gcp_USEast,df_gcp_USWest,df_gcp_USCentral,df_gcp_Practice_DA,df_gcp_Practice_CAI,df_bfsi_gcp,df_bfsi_aws,df_bfsi_dir=dataPrepartaionL2_FBProphet(df1,df2)\n",
    "#         Model_L2_Region_USEast,MAPE_L2_Region_USEast=training_L2_model_FBProphet(df_gcp_USEast,num_Val=number_validation_month,Database='Region_USEast')\n",
    "#         Model_L2_Region_USWest,MAPE_L2_Region_USWest=training_L2_model_FBProphet(df_gcp_USWest,num_Val=number_validation_month,Database='Region_USWest')\n",
    "#         Model_L2_Region_USCentral,MAPE_L2_Region_USCentral=training_L2_model_FBProphet(df_gcp_USCentral,num_Val=number_validation_month,Database='Region_USCentral')\n",
    "\n",
    "#         Model_L2_Practice_DA,MAPE_L2_Practice_DA=training_L2_model_FBProphet(df_gcp_Practice_DA,num_Val=number_validation_month,Database='Practice_DA')\n",
    "#         Model_L2_Practice_CAI,MAPE_L2_Practice_CAI=training_L2_model_FBProphet(df_gcp_Practice_CAI,num_Val=number_validation_month,Database='Practice_CAI')\n",
    "\n",
    "#         Model_L2_BFSI_GCP,MAPE_L2_BFSI_GCP=training_L2_model_FBProphet(df_bfsi_gcp,num_Val=number_validation_month,Database='BFSI_GCP')\n",
    "#         Model_L2_BFSI_AWS,MAPE_L2_BFSI_AWS=training_L2_model_FBProphet(df_bfsi_aws,num_Val=number_validation_month,Database='BFSI_AWS')\n",
    "#         Model_L2_BFSI_DIR,MAPE_L2_BFSI_DIR=training_L2_model_FBProphet(df_bfsi_dir,num_Val=number_validation_month,Database='BFSI_DIR')\n",
    "\n",
    "#         save_training_model_L2(Model_L2_BFSI_GCP,Model_L2_BFSI_AWS,Model_L2_BFSI_DIR,Model_L2_Region_USEast,Model_L2_Region_USWest,Model_L2_Region_USCentral,Model_L2_Practice_DA,Model_L2_Practice_CAI)        \n",
    "#         print('Validation result for L2-level')\n",
    "#         print('BFSI-GCP')\n",
    "#         print(MAPE_L2_BFSI_GCP)\n",
    "#         print('BFSI-AWS')\n",
    "#         print(MAPE_L2_BFSI_AWS)\n",
    "#         print('BFSI-Direct')\n",
    "#         print(MAPE_L2_BFSI_DIR)\n",
    "#         print('GCP-Region-USEast')\n",
    "#         print(MAPE_L2_Region_USEast)\n",
    "#         print('GCP-Region-USWest')\n",
    "#         print(MAPE_L2_Region_USWest) \n",
    "#         print('GCP-Region-USCentral')\n",
    "#         print(MAPE_L2_Region_USCentral)         \n",
    "#         print('GCP-Practice-Conversational AI')\n",
    "#         print(MAPE_L2_Practice_CAI) \n",
    "#         print('GCP-Practice- Data Analytics')\n",
    "#         print(MAPE_L2_Practice_DA)\n",
    "        \n",
    "# #         print('L2 section')\n",
    "# #         print('df1 size=',df1.shape)\n",
    "# #         print('df2 size=',df2.shape)        \n",
    "# #         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "# #         df = pd.DataFrame()\n",
    "# #         df['Date']=date_ref['ds']\n",
    "# #         df['Prediction']=bfsi_GCP\n",
    "# #         print('Prediction for L2-level: BFSI-GCP')\n",
    "# #         print(df)\n",
    "    \n",
    "# lev_button = widgets.Button(\n",
    "# description='Next',\n",
    "# disabled=False,\n",
    "# button_style='info', \n",
    "# tooltip='Confirm the model level selection'\n",
    "# )\n",
    "\n",
    "# lev_button.on_click(selectlevel)\n",
    "# Bt0.on_click(train_model_L0)\n",
    "# Bt1.on_click(train_model_L1)\n",
    "# Bt2.on_click(train_model_L2)\n",
    "\n",
    "# style = {'description_width': 'initial'}\n",
    "# Validation_months=widgets.BoundedIntText(\n",
    "#     value=2,\n",
    "#     min=0,\n",
    "#     max=10,\n",
    "#     step=1,\n",
    "#     description='Choose num of Validation months:',\n",
    "#     disabled=False, style=style\n",
    "# )\n",
    "\n",
    "# Label_Train_21=widgets.HTML(value=\"<h2> Select level of training/ tesing</h2>\")\n",
    "# Label_Train_22=widgets.HTML(value=\"<h3> What are Levels? </h3>\")\n",
    "# Label_Train_23=widgets.HTML(value=\"<h3> There are 3 levels within which the model can generate predictions. These are - L0, L1 and L2. </h3>\")\n",
    "# Label_Train_24=widgets.HTML(value=\"<h3> L0 - For predictions at Quantiphi level </h3>\")\n",
    "# Label_Train_25=widgets.HTML(value=\"<h3> L1 - For predictions at Channel vs. BU level </h3>\")\n",
    "# Label_Train_26=widgets.HTML(value=\"<h3> L2 - For further prediction within a Channel and BU . In channels, only GCP has been considered for prediction due to sufficient data volume. Within GCP predictions can be made for different regions & practices. </h3>\")\n",
    "# Label_Train_27=widgets.HTML(value=\"<h3> IN BUs, only BFSI has been considered for predictions due to sufficient data volume. Within BFSI, prediction can be made for deals that are in AWS, GCP and Direct </h3>\")\n",
    "# Label_Train_28=widgets.HTML(value=\"<h4> Note: For demo purpose the hyperparameter length is reduced </h4>\")\n",
    "  \n",
    "# label_boxB=widgets.VBox([Label_Train_21,Label_Train_22,Label_Train_23,Label_Train_24,Label_Train_25,Label_Train_26,Label_Train_27,Label_Train_28])\n",
    "# left_box1B = widgets.HBox([level_selector, lev_button])\n",
    "# #left_box2 = widgets.HBox([Validation_months, outputlev])\n",
    "# left_box3B = widgets.VBox([left_boxA,label_boxB,left_box1B,outputlev])\n",
    "# #left_box3\n",
    "\n",
    "# # left_box1=widgets.HBox([uploader_df1,get_data_button])\n",
    "# # left_box2Train=widgets.HBox([uploader_df2Train,get_data_button2Train])\n",
    "# # # left_box1\n",
    "# # left_box2=widgets.HBox([uploader_df2,get_data_button2])\n",
    "# # # left_box2\n",
    "# # left_box=widgets.VBox([Label1,left_box1,Label2Train,left_box2Train,Label2,left_box2])\n",
    "# # left_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8024db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a33cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction using newly trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7513429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputlev1 = widgets.Output()\n",
    "\n",
    "# level1_selector = widgets.RadioButtons(\n",
    "#                          options=['GCP','AWS','BFSI', 'TMEG', 'HCLS'],\n",
    "#                          value=None,\n",
    "#                          description='Select Level: ',\n",
    "#                          disabled=False,\n",
    "# #     layout=widgets.Layout(width='100%')\n",
    "# )\n",
    "\n",
    "# level2_selector = widgets.RadioButtons(\n",
    "#                          options=['BFSI-AWS', 'BFSI-Direct', 'BFSI-GCP', 'Region-USCentral','Region-USEast','Region-USWest'],\n",
    "#                          value=None,\n",
    "#                          description='Select Level: ',\n",
    "#                          disabled=False,\n",
    "# )\n",
    "# B = widgets.Button(\n",
    "#  description='Format Data',\n",
    "#  disabled=False,\n",
    "#  button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "#  tooltip='Click me',\n",
    "#  icon='run'\n",
    "# )\n",
    "# style = {'description_width': 'initial'}\n",
    "# B0 = widgets.Button(\n",
    "#  description='Format Data and predict',\n",
    "#  disabled=False,\n",
    "#  button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "#  tooltip='Click for Format Data and predict',\n",
    "#  icon='run',style=style\n",
    "# )\n",
    "\n",
    "# B11 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B12 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B13 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B14 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B15 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "\n",
    "# B21 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B22 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B23 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B24 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B25 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "# B26 = widgets.Button(description='Format Data and predict',disabled=False,button_style='info', tooltip='Click for Format Data and predict',icon='run')\n",
    "\n",
    "# def on_change1(change):\n",
    "#     with outputlev:\n",
    "#         if change['type'] == 'change' and change['name'] == 'value':\n",
    "#             if change['new'] == 'GCP':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP Selected')\n",
    "#                     display(B11)\n",
    "#             elif change['new'] == 'BFSI':\n",
    "#                 with outputlev1:\n",
    "#                     print('BFSI Selected')\n",
    "#                     display(B13)\n",
    "#             elif change['new'] == 'AWS':\n",
    "#                 with outputlev1:\n",
    "#                     print('AWS Selected')  \n",
    "#                     display(B12)\n",
    "#             elif change['new'] == 'TMEG':\n",
    "#                 with outputlev1:\n",
    "#                     print('TMEG Selected')\n",
    "#                     display(B15)\n",
    "#             elif change['new'] == 'HCLS':\n",
    "#                 with outputlev1:\n",
    "#                     print('HCLS Selected')\n",
    "#                     display(B14)\n",
    "                    \n",
    "# def on_change2(change):\n",
    "#     with outputlev1:\n",
    "#         if change['type'] == 'change' and change['name'] == 'value':\n",
    "#             if change['new'] == 'Region-USCentral':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP-Region US Central Selected')\n",
    "#                     display(B24)\n",
    "#             elif change['new'] =='Region-USEast':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP-Region US East Selected')\n",
    "#                     display(B25)\n",
    "#             elif change['new'] =='Region-USWest':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP-Region US West Selected')\n",
    "#                     display(B26)        \n",
    "#             elif change['new'] =='Practice-CAI':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP-Practice-Conversational AI Selected')\n",
    "#                     display(B27)                     \n",
    "#             elif change['new'] == 'Practice-DA':\n",
    "#                 with outputlev1:\n",
    "#                     print('GCP-Practice-Data Analytics Selected')\n",
    "#                     display(B28)\n",
    "#             elif change['new'] == 'BFSI-AWS':\n",
    "#                 with outputlev1:\n",
    "#                     print('BFSI-AWS Selected') \n",
    "#                     display(B22)\n",
    "#             elif change['new'] == 'BFSI-Direct':\n",
    "#                 with outputlev1:\n",
    "#                     print('BFSI-Direct Selected')\n",
    "#                     display(B23)\n",
    "#             elif change['new'] == 'BFSI-GCP':\n",
    "#                 with outputlev1:\n",
    "#                     print('BFSI-GCP Selected')   \n",
    "#                     display(B21)\n",
    "\n",
    "# def selectlevel(button):\n",
    "#     with outputlev1:\n",
    "#         selection = level_selector.get_interact_value()\n",
    "#         if (selection == \"L0\"):\n",
    "#             with outputlev1:\n",
    "#                 print('L0 Level Selected')\n",
    "#                 display(B0)                 \n",
    "#         elif (selection ==\"L1\"):\n",
    "#                 level1_selector.observe(on_change1)\n",
    "#                 display(level1_selector)\n",
    "\n",
    "#         elif (selection ==\"L2\"):\n",
    "#                 level2_selector.observe(on_change2)\n",
    "#                 display(level2_selector)\n",
    "\n",
    "# def prediction_L0(button):\n",
    "#     with outputlev1:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L0,date_ref=L0_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L0\n",
    "#         print('Prediction for L0-level')\n",
    "#         print(df)\n",
    "                  \n",
    "# def prediction_L1_GCP(button):\n",
    "#     with outputlev1:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L1_GCP\n",
    "#         print('Prediction for L1-level: GCP')\n",
    "#         print(df)        \n",
    "\n",
    "# def prediction_L1_AWS(button):\n",
    "#     with outputlev1:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L1_AWS\n",
    "#         print('Prediction for L1-level: AWS')\n",
    "#         print(df)\n",
    "        \n",
    "# def prediction_L1_BFSI(button):\n",
    "#     with outputlev1:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L1_BFSI\n",
    "#         print('Prediction for L1-level: BFSI')\n",
    "#         print(df)\n",
    "\n",
    "# def prediction_L1_HCLS(button):\n",
    "#     with outputlev1:\n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L1_HCLS\n",
    "#         print('Prediction for L1-level: HCLS')\n",
    "#         print(df)\n",
    "\n",
    "# def prediction_L1_TMEG(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         Predict_L1_GCP,Predict_L1_AWS,Predict_L1_BFSI,Predict_L1_HCLS,Predict_L1_TMEG,date_ref=L1_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=Predict_L1_TMEG\n",
    "#         print('Prediction for L1-level: TMEG')\n",
    "#         print(df)\n",
    "\n",
    "       \n",
    "     \n",
    "# def prediction_L2_BFSI_GCP(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=bfsi_GCP\n",
    "#         print('Prediction for L2-level: BFSI-GCP')\n",
    "#         print(df)\n",
    "\n",
    "# def prediction_L2_BFSI_AWS(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=bfsi_AWS\n",
    "#         print('Prediction for L2-level: BFSI-AWS')\n",
    "#         print(df)\n",
    " \n",
    "     \n",
    "# def prediction_L2_BFSI_DIR(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=bfsi_DIR\n",
    "#         print('Prediction for L2-level: BFSI-Direct')\n",
    "#         print(df)\n",
    "\n",
    "\n",
    "# def prediction_L2_RegionUSCentral(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=USCentral\n",
    "#         print('Prediction for L2-level: Region-US Central')\n",
    "#         print(df)\n",
    "\n",
    "\n",
    "# def prediction_L2_RegionUSEast(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=USEast\n",
    "#         print('Prediction for L2-level: Region-US East')\n",
    "#         print(df)\n",
    "\n",
    "\n",
    "# def prediction_L2_RegionUSWest(button):\n",
    "#     with outputlev1:    \n",
    "#         df1=get_data.data\n",
    "#         df2=get_datadf2.data\n",
    "#         bfsi_GCP,bfsi_AWS,bfsi_DIR,USCentral,USEast,USWest,date_ref=L2_level_prediction_saved_model(df1,df2,saveflag_data='True')\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Date']=date_ref['ds']\n",
    "#         df['Prediction']=USWest\n",
    "#         print('Prediction for L2-level: Region-US West')\n",
    "#         print(df)\n",
    "            \n",
    "    \n",
    "# lev_button1 = widgets.Button(\n",
    "# description='Next',\n",
    "# disabled=False,\n",
    "# button_style='info', \n",
    "# tooltip='click to get prediction for test data'\n",
    "# )\n",
    "\n",
    "# lev_button1.on_click(selectlevel)\n",
    "# B0.on_click(prediction_L0)\n",
    "# B11.on_click(prediction_L1_GCP)\n",
    "# B12.on_click(prediction_L1_AWS)\n",
    "# B13.on_click(prediction_L1_BFSI)\n",
    "# B14.on_click(prediction_L1_HCLS)\n",
    "# B15.on_click(prediction_L1_TMEG)\n",
    "\n",
    "# B21.on_click(prediction_L2_BFSI_GCP)\n",
    "# B22.on_click(prediction_L2_BFSI_AWS)\n",
    "# B23.on_click(prediction_L2_BFSI_DIR)\n",
    "# B24.on_click(prediction_L2_RegionUSCentral)\n",
    "# B25.on_click(prediction_L2_RegionUSEast)\n",
    "# B26.on_click(prediction_L2_RegionUSWest) \n",
    "\n",
    "# Label_3C = widgets.HTML(value=\"<h2> Prediction using newly trained model</h2>\")\n",
    "# #Label2Train=widgets.Label(\"Please upload the 'Rev Projection Training sheet' file in .csv or .xlsx format\")\n",
    "# left_box5C = widgets.VBox([lev_button1,outputlev1])\n",
    "# widgets.VBox([left_box3B,Label_3C,left_box5C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a9600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
